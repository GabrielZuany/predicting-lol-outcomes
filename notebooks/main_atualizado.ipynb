{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2049733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import LabelEncoder\n",
    "from sklearn.base import defaultdict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59947c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>result</th>\n",
       "      <th>golddiffat15</th>\n",
       "      <th>xpdiffat15</th>\n",
       "      <th>csdiffat15</th>\n",
       "      <th>killsdiffat15</th>\n",
       "      <th>assistsdiffat15</th>\n",
       "      <th>golddiffat10</th>\n",
       "      <th>xpdiffat10</th>\n",
       "      <th>csdiffat10</th>\n",
       "      <th>...</th>\n",
       "      <th>OPP_EGR</th>\n",
       "      <th>OPP_MLR</th>\n",
       "      <th>OPP_FB%</th>\n",
       "      <th>OPP_FT%</th>\n",
       "      <th>OPP_F3T%</th>\n",
       "      <th>OPP_HLD%</th>\n",
       "      <th>OPP_DRG%</th>\n",
       "      <th>OPP_BN%</th>\n",
       "      <th>OPP_LNE%</th>\n",
       "      <th>OPP_JNG%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5018.0</td>\n",
       "      <td>4255.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1793.0</td>\n",
       "      <td>2365.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.1</td>\n",
       "      <td>-23.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>50</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>49.2</td>\n",
       "      <td>43.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>-1879.0</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>77.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>58</td>\n",
       "      <td>70</td>\n",
       "      <td>89</td>\n",
       "      <td>50.4</td>\n",
       "      <td>53.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>-579.0</td>\n",
       "      <td>-1643.0</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>77.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>58</td>\n",
       "      <td>70</td>\n",
       "      <td>89</td>\n",
       "      <td>50.4</td>\n",
       "      <td>53.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>3739.0</td>\n",
       "      <td>1118.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1746.0</td>\n",
       "      <td>824.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>63.9</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>48</td>\n",
       "      <td>60</td>\n",
       "      <td>48</td>\n",
       "      <td>51.6</td>\n",
       "      <td>50.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>-6390.0</td>\n",
       "      <td>-4569.0</td>\n",
       "      <td>-47.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-3500.0</td>\n",
       "      <td>-1882.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.8</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>49.7</td>\n",
       "      <td>42.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  result  golddiffat15  xpdiffat15  csdiffat15  killsdiffat15  \\\n",
       "0   10       1        5018.0      4255.0        86.0            5.0   \n",
       "1   22       0         573.0     -1879.0       -49.0            1.0   \n",
       "2   34       0        -579.0     -1643.0       -40.0           -1.0   \n",
       "3  106       1        3739.0      1118.0        53.0            1.0   \n",
       "4  118       0       -6390.0     -4569.0       -47.0          -10.0   \n",
       "\n",
       "   assistsdiffat15  golddiffat10  xpdiffat10  csdiffat10  ...  OPP_EGR  \\\n",
       "0              9.0        1793.0      2365.0        65.0  ...     23.1   \n",
       "1              4.0         759.0       171.0        -8.0  ...     77.2   \n",
       "2             -5.0          73.0        -1.0       -24.0  ...     77.2   \n",
       "3              0.0        1746.0       824.0        21.0  ...     63.9   \n",
       "4            -17.0       -3500.0     -1882.0       -18.0  ...     25.8   \n",
       "\n",
       "   OPP_MLR  OPP_FB%  OPP_FT%  OPP_F3T%  OPP_HLD%  OPP_DRG%  OPP_BN%  OPP_LNE%  \\\n",
       "0    -23.1        0        0        33        50        27        0      49.2   \n",
       "1     22.8      100      100       100        58        70       89      50.4   \n",
       "2     22.8      100      100       100        58        70       89      50.4   \n",
       "3     -3.9       67       67        67        48        60       48      51.6   \n",
       "4     -0.8       13       25        25        19        20       20      49.7   \n",
       "\n",
       "   OPP_JNG%  \n",
       "0      43.7  \n",
       "1      53.3  \n",
       "2      53.3  \n",
       "3      50.3  \n",
       "4      42.2  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = \"../data/jogosLoL2021.csv\"\n",
    "df = pd.read_csv(dataset_path, sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54924d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=\"id\", inplace=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1adfbd26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>golddiffat15</th>\n",
       "      <th>xpdiffat15</th>\n",
       "      <th>csdiffat15</th>\n",
       "      <th>killsdiffat15</th>\n",
       "      <th>assistsdiffat15</th>\n",
       "      <th>golddiffat10</th>\n",
       "      <th>xpdiffat10</th>\n",
       "      <th>csdiffat10</th>\n",
       "      <th>killsdiffat10</th>\n",
       "      <th>...</th>\n",
       "      <th>OPP_EGR</th>\n",
       "      <th>OPP_MLR</th>\n",
       "      <th>OPP_FB%</th>\n",
       "      <th>OPP_FT%</th>\n",
       "      <th>OPP_F3T%</th>\n",
       "      <th>OPP_HLD%</th>\n",
       "      <th>OPP_DRG%</th>\n",
       "      <th>OPP_BN%</th>\n",
       "      <th>OPP_LNE%</th>\n",
       "      <th>OPP_JNG%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.531894</td>\n",
       "      <td>276.489328</td>\n",
       "      <td>4.800417</td>\n",
       "      <td>-0.348135</td>\n",
       "      <td>0.173332</td>\n",
       "      <td>0.311089</td>\n",
       "      <td>102.689892</td>\n",
       "      <td>32.706452</td>\n",
       "      <td>0.719946</td>\n",
       "      <td>0.090898</td>\n",
       "      <td>...</td>\n",
       "      <td>44.814009</td>\n",
       "      <td>-6.222031</td>\n",
       "      <td>48.298945</td>\n",
       "      <td>43.971663</td>\n",
       "      <td>42.174681</td>\n",
       "      <td>45.288027</td>\n",
       "      <td>45.828754</td>\n",
       "      <td>41.541830</td>\n",
       "      <td>49.774583</td>\n",
       "      <td>48.389561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499012</td>\n",
       "      <td>3092.939045</td>\n",
       "      <td>2164.253849</td>\n",
       "      <td>41.919732</td>\n",
       "      <td>3.769752</td>\n",
       "      <td>7.180593</td>\n",
       "      <td>1520.042590</td>\n",
       "      <td>1138.075319</td>\n",
       "      <td>27.248651</td>\n",
       "      <td>2.371612</td>\n",
       "      <td>...</td>\n",
       "      <td>14.794485</td>\n",
       "      <td>16.023668</td>\n",
       "      <td>20.784422</td>\n",
       "      <td>22.695632</td>\n",
       "      <td>24.110996</td>\n",
       "      <td>18.265473</td>\n",
       "      <td>13.370805</td>\n",
       "      <td>21.333411</td>\n",
       "      <td>1.044415</td>\n",
       "      <td>4.023629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-13908.000000</td>\n",
       "      <td>-10397.000000</td>\n",
       "      <td>-181.000000</td>\n",
       "      <td>-22.000000</td>\n",
       "      <td>-34.000000</td>\n",
       "      <td>-7632.000000</td>\n",
       "      <td>-5829.000000</td>\n",
       "      <td>-109.000000</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>-59.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.300000</td>\n",
       "      <td>35.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1685.250000</td>\n",
       "      <td>-1344.250000</td>\n",
       "      <td>-27.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-865.000000</td>\n",
       "      <td>-691.250000</td>\n",
       "      <td>-17.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>35.100000</td>\n",
       "      <td>-15.200000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>49.200000</td>\n",
       "      <td>45.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>313.500000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>44.800000</td>\n",
       "      <td>-5.900000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>49.700000</td>\n",
       "      <td>48.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2247.000000</td>\n",
       "      <td>1334.250000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1037.500000</td>\n",
       "      <td>754.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>53.400000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>50.300000</td>\n",
       "      <td>50.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>13855.000000</td>\n",
       "      <td>11914.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>7043.000000</td>\n",
       "      <td>6464.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>98.100000</td>\n",
       "      <td>49.400000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>55.300000</td>\n",
       "      <td>64.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            result  golddiffat15    xpdiffat15   csdiffat15  killsdiffat15  \\\n",
       "count  8152.000000   8152.000000   8152.000000  8152.000000    8152.000000   \n",
       "mean      0.531894    276.489328      4.800417    -0.348135       0.173332   \n",
       "std       0.499012   3092.939045   2164.253849    41.919732       3.769752   \n",
       "min       0.000000 -13908.000000 -10397.000000  -181.000000     -22.000000   \n",
       "25%       0.000000  -1685.250000  -1344.250000   -27.000000      -2.000000   \n",
       "50%       1.000000    313.500000     26.000000     0.000000       0.000000   \n",
       "75%       1.000000   2247.000000   1334.250000    26.000000       2.000000   \n",
       "max       1.000000  13855.000000  11914.000000   183.000000      21.000000   \n",
       "\n",
       "       assistsdiffat15  golddiffat10   xpdiffat10   csdiffat10  killsdiffat10  \\\n",
       "count      8152.000000   8152.000000  8152.000000  8152.000000    8152.000000   \n",
       "mean          0.311089    102.689892    32.706452     0.719946       0.090898   \n",
       "std           7.180593   1520.042590  1138.075319    27.248651       2.371612   \n",
       "min         -34.000000  -7632.000000 -5829.000000  -109.000000     -15.000000   \n",
       "25%          -4.000000   -865.000000  -691.250000   -17.000000      -1.000000   \n",
       "50%           0.000000    115.000000    26.000000     1.000000       0.000000   \n",
       "75%           4.000000   1037.500000   754.000000    19.000000       1.000000   \n",
       "max          32.000000   7043.000000  6464.000000   137.000000      13.000000   \n",
       "\n",
       "       ...      OPP_EGR      OPP_MLR      OPP_FB%      OPP_FT%     OPP_F3T%  \\\n",
       "count  ...  8152.000000  8152.000000  8152.000000  8152.000000  8152.000000   \n",
       "mean   ...    44.814009    -6.222031    48.298945    43.971663    42.174681   \n",
       "std    ...    14.794485    16.023668    20.784422    22.695632    24.110996   \n",
       "min    ...     3.100000   -59.900000     0.000000     0.000000     0.000000   \n",
       "25%    ...    35.100000   -15.200000    33.000000    30.000000    25.000000   \n",
       "50%    ...    44.800000    -5.900000    50.000000    43.000000    43.000000   \n",
       "75%    ...    53.400000     4.100000    61.000000    59.000000    58.000000   \n",
       "max    ...    98.100000    49.400000   100.000000   100.000000   100.000000   \n",
       "\n",
       "          OPP_HLD%     OPP_DRG%      OPP_BN%     OPP_LNE%     OPP_JNG%  \n",
       "count  8152.000000  8152.000000  8152.000000  8152.000000  8152.000000  \n",
       "mean     45.288027    45.828754    41.541830    49.774583    48.389561  \n",
       "std      18.265473    13.370805    21.333411     1.044415     4.023629  \n",
       "min       0.000000     0.000000     0.000000    45.300000    35.500000  \n",
       "25%      33.000000    39.000000    29.000000    49.200000    45.900000  \n",
       "50%      48.000000    46.000000    43.000000    49.700000    48.700000  \n",
       "75%      58.000000    54.000000    56.000000    50.300000    50.800000  \n",
       "max     100.000000    94.000000   100.000000    55.300000    64.800000  \n",
       "\n",
       "[8 rows x 39 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19bc189",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Definição de seeds, variaveis, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92dcf3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "TARGET = \"result\"\n",
    "PRE_GAME_FEATURES = [\n",
    "    'WR', 'KD', 'GPR', 'GSPD', 'EGR', 'MLR', 'FB%', 'FT%', 'F3T%', \n",
    "    'HLD%', 'DRG%', 'BN%', 'LNE%', 'JNG%',\n",
    "    'OPP_WR', 'OPP_KD', 'OPP_GPR', 'OPP_GSPD', 'OPP_EGR', 'OPP_MLR',\n",
    "    'OPP_FB%', 'OPP_FT%', 'OPP_F3T%', 'OPP_HLD%', 'OPP_DRG%', \n",
    "    'OPP_BN%', 'OPP_LNE%', 'OPP_JNG%'\n",
    "]\n",
    "\n",
    "AT_10M_FEATURES = [\n",
    "    'golddiffat10',\n",
    "    'xpdiffat10',\n",
    "    'csdiffat10',   \n",
    "    'killsdiffat10',\n",
    "    'assistsdiffat10'\n",
    "]\n",
    "\n",
    "AT_15M_FEATURES = [\n",
    "    'golddiffat15', 'xpdiffat15', 'csdiffat15', \n",
    "    'killsdiffat15', 'assistsdiffat15'\n",
    "]\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "# Example: Move a tensor to the selected device\n",
    "# tensor = torch.tensor([1.0, 2.0, 3.0]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38fae145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se há colunas categóricas que precisam ser codificadas:\n",
    "feature_columns = None   \n",
    "le = LabelEncoder()\n",
    "\n",
    "# Separar features e target\n",
    "if feature_columns is None:\n",
    "    X = df.drop(columns=[TARGET]).values\n",
    "    feature_names = df.drop(columns=[TARGET]).columns.tolist()\n",
    "else:\n",
    "    X = df[feature_columns].values\n",
    "    feature_names = feature_columns\n",
    "\n",
    "y = df[TARGET].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70c27a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset carregado: 8152 amostras, 38 features, 2 classes\n",
      "Distribuição das classes: {0: np.int64(3816), 1: np.int64(4336)}\n",
      "Features: ['golddiffat15', 'xpdiffat15', 'csdiffat15', 'killsdiffat15', 'assistsdiffat15']...\n"
     ]
    }
   ],
   "source": [
    "# Informações do dataset\n",
    "n_samples, n_features = X.shape\n",
    "n_classes = len(np.unique(y))\n",
    "class_distribution = np.bincount(y)\n",
    "\n",
    "print(f\"Dataset carregado: {n_samples} amostras, {n_features} features, {n_classes} classes\")\n",
    "print(f\"Distribuição das classes: {dict(zip(range(n_classes), class_distribution))}\")\n",
    "print(f\"Features: {feature_names[:5]}{'...' if len(feature_names) > 5 else ''}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267712f6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f197c085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cv_random_forest(\n",
    "    df, \n",
    "    feature_columns, \n",
    "    target_column='result', \n",
    "    rf_hyperparameters=None, \n",
    "    n_classes=2, \n",
    "    n_outer_folds=10, \n",
    "    n_inner_folds=4, \n",
    "    n_rounds=3, \n",
    "    random_state=36854321\n",
    "):\n",
    "    if rf_hyperparameters is None:\n",
    "        rf_hyperparameters = {'n_estimators': [5, 10, 15, 25], 'max_depth': [10, None]}\n",
    "    print(f\"Grid de hiperparâmetros: {np.prod([len(v) for v in rf_hyperparameters.values()])} combinações\")\n",
    "\n",
    "    X = df[feature_columns].values\n",
    "    y = df[target_column].values\n",
    "\n",
    "    resultados_completos = defaultdict(list)\n",
    "    detalhes_rodadas = []\n",
    "\n",
    "    for rodada in range(n_rounds):\n",
    "        print(f\"\\nRODADA {rodada + 1}/{n_rounds}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        indices = np.random.permutation(len(X))\n",
    "        X_shuffled = X[indices]\n",
    "        y_shuffled = y[indices]\n",
    "\n",
    "        outer_cv = StratifiedKFold(n_splits=n_outer_folds, shuffle=True, random_state=random_state)\n",
    "        acuracias_fold_externo = []\n",
    "        detalhes_folds = []\n",
    "\n",
    "        for fold_externo, (train_idx, test_idx) in enumerate(outer_cv.split(X_shuffled, y_shuffled)):\n",
    "            print(f\"Fold Externo {fold_externo + 1}/{n_outer_folds}\", end=\" - \")\n",
    "\n",
    "            X_train_outer = X_shuffled[train_idx]\n",
    "            X_test_outer = X_shuffled[test_idx]\n",
    "            y_train_outer = y_shuffled[train_idx]\n",
    "            y_test_outer = y_shuffled[test_idx]\n",
    "\n",
    "            train_dist = np.bincount(y_train_outer, minlength=n_classes)\n",
    "            test_dist = np.bincount(y_test_outer, minlength=n_classes)\n",
    "\n",
    "            inner_cv = StratifiedKFold(n_splits=n_inner_folds, shuffle=True, random_state=random_state)\n",
    "\n",
    "            rf = RandomForestClassifier(random_state=random_state, n_jobs=-1)\n",
    "            grid_search = GridSearchCV(\n",
    "                rf,\n",
    "                rf_hyperparameters,\n",
    "                cv=inner_cv,\n",
    "                scoring='accuracy',\n",
    "                n_jobs=-1,\n",
    "                verbose=0\n",
    "            ) # Otimiza hiperparâmetros para cada fold externo e usa validação cruzada interna (4 folds) -> perforance melhorada\n",
    "            \n",
    "            grid_search.fit(X_train_outer, y_train_outer)\n",
    "            y_pred = grid_search.predict(X_test_outer)\n",
    "            acuracia = accuracy_score(y_test_outer, y_pred)\n",
    "            acuracias_fold_externo.append(acuracia)\n",
    "\n",
    "            detalhes_fold = {\n",
    "                'fold': fold_externo + 1,\n",
    "                'melhores_params': grid_search.best_params_,\n",
    "                'acuracia_validacao_interna': grid_search.best_score_,\n",
    "                'acuracia_teste_externo': acuracia,\n",
    "                'tamanho_treino': len(X_train_outer),\n",
    "                'tamanho_teste': len(X_test_outer),\n",
    "                'distribuicao_treino': train_dist.tolist(),\n",
    "                'distribuicao_teste': test_dist.tolist()\n",
    "            }\n",
    "            detalhes_folds.append(detalhes_fold)\n",
    "\n",
    "            print(f\"Acurácia: {acuracia:.4f} | Val.Interna: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "        acuracia_media_rodada = np.mean(acuracias_fold_externo)\n",
    "        desvio_rodada = np.std(acuracias_fold_externo)\n",
    "\n",
    "        print(f\"\\n  Resultados da Rodada {rodada + 1}:\")\n",
    "        print(f\"     Acurácia Média: {acuracia_media_rodada:.4f} ± {desvio_rodada:.4f}\")\n",
    "        print(f\"     Min: {min(acuracias_fold_externo):.4f} | Max: {max(acuracias_fold_externo):.4f}\")\n",
    "\n",
    "        resultados_completos['rodada'].append(rodada + 1)\n",
    "        resultados_completos['acuracia_media'].append(acuracia_media_rodada)\n",
    "        resultados_completos['desvio_padrao'].append(desvio_rodada)\n",
    "        resultados_completos['acuracias_folds'].append(acuracias_fold_externo)\n",
    "\n",
    "        detalhes_rodadas.append({\n",
    "            'rodada': rodada + 1,\n",
    "            'acuracia_media': acuracia_media_rodada,\n",
    "            'desvio_padrao': desvio_rodada,\n",
    "            'detalhes_folds': detalhes_folds\n",
    "        })\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"RESULTADO FINAL DAS 3 RODADAS\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    acuracias_finais = resultados_completos['acuracia_media']\n",
    "    acuracia_final_media = np.mean(acuracias_finais)\n",
    "    desvio_final = np.std(acuracias_finais)\n",
    "\n",
    "    print(f\"Acurácia Final do Random Forest: {acuracia_final_media:.4f} ± {desvio_final:.4f}\")\n",
    "    print(f\"Intervalo de Confiança (~95%): [{acuracia_final_media - 2*desvio_final:.4f}, {acuracia_final_media + 2*desvio_final:.4f}]\")\n",
    "\n",
    "    return {\n",
    "        'resultados_completos': resultados_completos,\n",
    "        'detalhes_rodadas': detalhes_rodadas,\n",
    "        'acuracia_final_media': acuracia_final_media,\n",
    "        'desvio_final': desvio_final\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee3980f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cv_classifier(\n",
    "    df, \n",
    "    feature_columns, \n",
    "    classifier,\n",
    "    classifier_name,\n",
    "    hyperparameters,\n",
    "    target_column='result', \n",
    "    n_classes=2, \n",
    "    n_outer_folds=10, \n",
    "    n_inner_folds=4, \n",
    "    n_rounds=3, \n",
    "    random_state=36854321\n",
    "):\n",
    "    \"\"\"\n",
    "    Função genérica para validação cruzada aninhada com qualquer classificador\n",
    "    \n",
    "    Parâmetros:\n",
    "    - df: DataFrame com os dados\n",
    "    - feature_columns: lista das colunas de features\n",
    "    - classifier: instância do classificador (ex: RandomForestClassifier(), MLPClassifier())\n",
    "    - classifier_name: nome do classificador para exibição (ex: 'Random Forest', 'MLP', 'KNN')\n",
    "    - hyperparameters: dicionário com hiperparâmetros do classificador\n",
    "    - target_column: nome da coluna target (padrão: 'result')\n",
    "    - n_classes: número de classes (padrão: 2)\n",
    "    - n_outer_folds: número de folds externos (padrão: 10)\n",
    "    - n_inner_folds: número de folds internos (padrão: 4)\n",
    "    - n_rounds: número de rodadas (padrão: 3)\n",
    "    - random_state: seed para reprodutibilidade\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Grid de hiperparâmetros: {np.prod([len(v) for v in hyperparameters.values()])} combinações\")\n",
    "    print(f\"Classificador: {classifier_name}\")\n",
    "\n",
    "    X = df[feature_columns].values\n",
    "    y = df[target_column].values\n",
    "\n",
    "    resultados_completos = defaultdict(list)\n",
    "    detalhes_rodadas = []\n",
    "\n",
    "    for rodada in range(n_rounds):\n",
    "        print(f\"\\nRODADA {rodada + 1}/{n_rounds}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        indices = np.random.permutation(len(X))\n",
    "        X_shuffled = X[indices]\n",
    "        y_shuffled = y[indices]\n",
    "\n",
    "        outer_cv = StratifiedKFold(n_splits=n_outer_folds, shuffle=True, random_state=random_state)\n",
    "        acuracias_fold_externo = []\n",
    "        detalhes_folds = []\n",
    "\n",
    "        for fold_externo, (train_idx, test_idx) in enumerate(outer_cv.split(X_shuffled, y_shuffled)):\n",
    "            print(f\"Fold Externo {fold_externo + 1}/{n_outer_folds}\", end=\" - \")\n",
    "\n",
    "            X_train_outer = X_shuffled[train_idx]\n",
    "            X_test_outer = X_shuffled[test_idx]\n",
    "            y_train_outer = y_shuffled[train_idx]\n",
    "            y_test_outer = y_shuffled[test_idx]\n",
    "\n",
    "            train_dist = np.bincount(y_train_outer, minlength=n_classes)\n",
    "            test_dist = np.bincount(y_test_outer, minlength=n_classes)\n",
    "\n",
    "            inner_cv = StratifiedKFold(n_splits=n_inner_folds, shuffle=True, random_state=random_state)\n",
    "\n",
    "            # Clona o classificador para cada fold para evitar problemas de estado\n",
    "            from sklearn.base import clone\n",
    "            clf = clone(classifier)\n",
    "            \n",
    "            grid_search = GridSearchCV(\n",
    "                clf,\n",
    "                hyperparameters,\n",
    "                cv=inner_cv,\n",
    "                scoring='accuracy',\n",
    "                n_jobs=-1,\n",
    "                verbose=0\n",
    "            ) # Otimiza hiperparâmetros para cada fold externo e usa validação cruzada interna (4 folds) -> performance melhorada\n",
    "            \n",
    "            grid_search.fit(X_train_outer, y_train_outer)\n",
    "            y_pred = grid_search.predict(X_test_outer)\n",
    "            acuracia = accuracy_score(y_test_outer, y_pred)\n",
    "            acuracias_fold_externo.append(acuracia)\n",
    "\n",
    "            detalhes_fold = {\n",
    "                'fold': fold_externo + 1,\n",
    "                'melhores_params': grid_search.best_params_,\n",
    "                'acuracia_validacao_interna': grid_search.best_score_,\n",
    "                'acuracia_teste_externo': acuracia,\n",
    "                'tamanho_treino': len(X_train_outer),\n",
    "                'tamanho_teste': len(X_test_outer),\n",
    "                'distribuicao_treino': train_dist.tolist(),\n",
    "                'distribuicao_teste': test_dist.tolist()\n",
    "            }\n",
    "            detalhes_folds.append(detalhes_fold)\n",
    "\n",
    "            print(f\"Acurácia: {acuracia:.4f} | Val.Interna: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "        acuracia_media_rodada = np.mean(acuracias_fold_externo)\n",
    "        desvio_rodada = np.std(acuracias_fold_externo)\n",
    "\n",
    "        print(f\"\\n  Resultados da Rodada {rodada + 1}:\")\n",
    "        print(f\"     Acurácia Média: {acuracia_media_rodada:.4f} ± {desvio_rodada:.4f}\")\n",
    "        print(f\"     Min: {min(acuracias_fold_externo):.4f} | Max: {max(acuracias_fold_externo):.4f}\")\n",
    "\n",
    "        resultados_completos['rodada'].append(rodada + 1)\n",
    "        resultados_completos['acuracia_media'].append(acuracia_media_rodada)\n",
    "        resultados_completos['desvio_padrao'].append(desvio_rodada)\n",
    "        resultados_completos['acuracias_folds'].append(acuracias_fold_externo)\n",
    "\n",
    "        detalhes_rodadas.append({\n",
    "            'rodada': rodada + 1,\n",
    "            'acuracia_media': acuracia_media_rodada,\n",
    "            'desvio_padrao': desvio_rodada,\n",
    "            'detalhes_folds': detalhes_folds\n",
    "        })\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"RESULTADO FINAL DAS 3 RODADAS\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    acuracias_finais = resultados_completos['acuracia_media']\n",
    "    acuracia_final_media = np.mean(acuracias_finais)\n",
    "    desvio_final = np.std(acuracias_finais)\n",
    "\n",
    "    print(f\"Acurácia Final do {classifier_name}: {acuracia_final_media:.4f} ± {desvio_final:.4f}\")\n",
    "    print(f\"Intervalo de Confiança (~95%): [{acuracia_final_media - 2*desvio_final:.4f}, {acuracia_final_media + 2*desvio_final:.4f}]\")\n",
    "\n",
    "    return {\n",
    "        'resultados_completos': resultados_completos,\n",
    "        'detalhes_rodadas': detalhes_rodadas,\n",
    "        'acuracia_final_media': acuracia_final_media,\n",
    "        'desvio_final': desvio_final,\n",
    "        'classifier_name': classifier_name\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a662b8",
   "metadata": {},
   "source": [
    "---\n",
    "# HeterogeneousBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38721b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.utils.validation import check_X_y, check_array\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from collections import Counter\n",
    "import warnings\n",
    "\n",
    "class HeterogeneousBoostingClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    Heterogeneous Boosting Classifier\n",
    "    \n",
    "    Um classificador ensemble que combina diferentes tipos de classificadores base\n",
    "    (Decision Tree, Naive Bayes, MLP, KNN) usando boosting com votação majoritária.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_estimators : int, default=10\n",
    "        Número de classificadores base que comporão o ensemble.\n",
    "    \n",
    "    random_state : int, RandomState instance or None, default=None\n",
    "        Controla a aleatoriedade da seleção de exemplos com reposição.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    classes_ : ndarray of shape (n_classes,)\n",
    "        As classes únicas encontradas durante o ajuste.\n",
    "    \n",
    "    n_classes_ : int\n",
    "        Número de classes.\n",
    "    \n",
    "    most_frequent_class_ : class label\n",
    "        A classe mais frequente na base de treino.\n",
    "    \n",
    "    estimators_ : list\n",
    "        Lista dos classificadores selecionados para o ensemble.\n",
    "    \n",
    "    X_train_ : ndarray\n",
    "        Dados de treino originais armazenados para referência.\n",
    "    \n",
    "    y_train_ : ndarray\n",
    "        Rótulos de treino originais armazenados para referência.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_estimators=10, random_state=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def _create_base_classifiers(self):\n",
    "        \"\"\"Cria os classificadores base com parâmetros default do sklearn\"\"\"\n",
    "        return {\n",
    "            'NB': GaussianNB(),\n",
    "            'DT': DecisionTreeClassifier(random_state=self.random_state),\n",
    "            'MLP': MLPClassifier(random_state=self.random_state, max_iter=1000),\n",
    "            'KNN': KNeighborsClassifier()\n",
    "        }\n",
    "    \n",
    "    def _roulette_wheel_selection(self, X, y, weights):\n",
    "        \"\"\"\n",
    "        Seleciona exemplos com reposição usando o método da roleta\n",
    "        baseado nos pesos dos exemplos.\n",
    "        \"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        \n",
    "        # Verifica se há pesos inválidos (NaN, inf, ou negativos)\n",
    "        if np.any(np.isnan(weights)) or np.any(np.isinf(weights)) or np.any(weights < 0):\n",
    "            # Se há pesos inválidos, reinicia com pesos uniformes\n",
    "            weights = np.ones(n_samples, dtype=float)\n",
    "        \n",
    "        # Verifica se todos os pesos são zero\n",
    "        if np.sum(weights) == 0:\n",
    "            weights = np.ones(n_samples, dtype=float)\n",
    "        \n",
    "        # Normaliza os pesos para que somem 1\n",
    "        normalized_weights = weights / np.sum(weights)\n",
    "        \n",
    "        # Verifica novamente se a normalização gerou NaN\n",
    "        if np.any(np.isnan(normalized_weights)):\n",
    "            normalized_weights = np.ones(n_samples, dtype=float) / n_samples\n",
    "        \n",
    "        # Seleciona índices com base nos pesos (com reposição)\n",
    "        selected_indices = np.random.choice(\n",
    "            n_samples, \n",
    "            size=n_samples, \n",
    "            replace=True, \n",
    "            p=normalized_weights\n",
    "        )\n",
    "        \n",
    "        return X[selected_indices], y[selected_indices], selected_indices\n",
    "    \n",
    "    def _evaluate_classifier(self, classifier, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Treina e avalia o desempenho de um classificador nos dados de treino\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "                warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "                # Treina o classificador\n",
    "                classifier.fit(X_train, y_train)\n",
    "                # Testa no mesmo conjunto (conforme pseudocódigo)\n",
    "                predictions = classifier.predict(X_train)\n",
    "                # Calcula acurácia\n",
    "                accuracy = np.mean(predictions == y_train)\n",
    "                return accuracy, predictions, classifier\n",
    "        except Exception as e:\n",
    "            # Em caso de erro, retorna acurácia 0\n",
    "            print(f\"Erro ao treinar classificador: {e}\")\n",
    "            return 0.0, np.full(len(y_train), y_train[0]), classifier\n",
    "    \n",
    "    def _select_best_classifier(self, results):\n",
    "        \"\"\"\n",
    "        Seleciona o melhor classificador baseado na acurácia.\n",
    "        Em caso de empate, usa a preferência: MLP, DT, KNN, NB\n",
    "        \"\"\"\n",
    "        preference_order = ['MLP', 'DT', 'KNN', 'NB']\n",
    "        \n",
    "        # Encontra a melhor acurácia\n",
    "        max_accuracy = max(acc for acc, _, _, _ in results.values())\n",
    "        \n",
    "        # Encontra classificadores com melhor acurácia\n",
    "        best_classifiers = [name for name, (acc, _, _, _) in results.items() \n",
    "                          if acc == max_accuracy]\n",
    "        \n",
    "        # Aplica ordem de preferência em caso de empate\n",
    "        for preferred in preference_order:\n",
    "            if preferred in best_classifiers:\n",
    "                return preferred, results[preferred]\n",
    "        \n",
    "        # Fallback (não deveria acontecer)\n",
    "        return list(best_classifiers)[0], results[list(best_classifiers)[0]]\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Ajusta o classificador Heterogeneous Boosting.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Dados de treino.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Rótulos de treino.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Retorna self.\n",
    "        \"\"\"\n",
    "        # Validação de entrada\n",
    "        X, y = check_X_y(X, y)\n",
    "        \n",
    "        # Armazena dados de treino originais\n",
    "        self.X_train_ = X.copy()\n",
    "        self.y_train_ = y.copy()\n",
    "        \n",
    "        # Armazena classes únicas\n",
    "        self.classes_ = unique_labels(y)\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "        \n",
    "        # Encontra e guarda a classe mais frequente\n",
    "        class_counts = Counter(y)\n",
    "        self.most_frequent_class_ = class_counts.most_common(1)[0][0]\n",
    "        \n",
    "        # Inicializa pesos dos exemplos com valor 1 para todos\n",
    "        weights = np.ones(X.shape[0], dtype=float)\n",
    "        \n",
    "        # Inicializa lista de classificadores do ensemble\n",
    "        self.estimators_ = []\n",
    "        \n",
    "        # Configura random state para reprodutibilidade\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "        \n",
    "        # Repete n_estimators vezes\n",
    "        for iteration in range(self.n_estimators):\n",
    "            # CORREÇÃO: Primeiro classificador usa base original, demais usam seleção com roleta\n",
    "            if iteration == 0:\n",
    "                # Primeiro classificador: usa base de treino original\n",
    "                X_train_iter = X\n",
    "                y_train_iter = y\n",
    "                selected_indices = np.arange(len(y))\n",
    "            else:\n",
    "                # Demais classificadores: usa seleção com método da roleta\n",
    "                X_train_iter, y_train_iter, selected_indices = self._roulette_wheel_selection(X, y, weights)\n",
    "            \n",
    "            # Para cada um dos métodos de classificação (NB, DT, MLP, KNN)\n",
    "            base_classifiers = self._create_base_classifiers()\n",
    "            results = {}\n",
    "            \n",
    "            for name, classifier in base_classifiers.items():\n",
    "                # Treina e testa o classificador nos exemplos selecionados\n",
    "                accuracy, predictions, trained_classifier = self._evaluate_classifier(\n",
    "                    classifier, X_train_iter, y_train_iter\n",
    "                )\n",
    "                results[name] = (accuracy, predictions, trained_classifier, selected_indices)\n",
    "            \n",
    "            # Escolhe o classificador com melhor desempenho\n",
    "            best_name, (best_accuracy, best_predictions, best_classifier, best_indices) = \\\n",
    "                self._select_best_classifier(results)\n",
    "            \n",
    "            # Adiciona o melhor classificador ao combinado\n",
    "            self.estimators_.append(best_classifier)\n",
    "            \n",
    "            # Dobra o peso dos exemplos classificados de forma errônea\n",
    "            # CORREÇÃO: Para o primeiro classificador, usar índices diretos\n",
    "            if iteration == 0:\n",
    "                # Primeiro classificador: atualiza pesos baseado na predição na base original\n",
    "                for i in range(len(y)):\n",
    "                    if best_predictions[i] != y[i]:\n",
    "                        weights[i] *= 2.0\n",
    "            else:\n",
    "                # Demais classificadores: atualiza pesos dos exemplos originais correspondentes\n",
    "                for i, original_idx in enumerate(best_indices):\n",
    "                    if best_predictions[i] != y_train_iter[i]:\n",
    "                        weights[original_idx] *= 2.0\n",
    "            \n",
    "            # Verifica se os pesos se tornaram muito grandes (overflow protection)\n",
    "            if np.any(weights > 1e10):\n",
    "                weights = weights / np.max(weights) * 1000\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Prediz classes para as amostras em X usando votação majoritária.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Amostras para predição.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        y_pred : ndarray of shape (n_samples,)\n",
    "            Classes preditas.\n",
    "        \"\"\"\n",
    "        # Validação de entrada\n",
    "        X = check_array(X)\n",
    "        \n",
    "        # Verifica se o modelo foi treinado\n",
    "        if not hasattr(self, 'estimators_') or len(self.estimators_) == 0:\n",
    "            raise ValueError(\"Este modelo não foi treinado ainda. Chame 'fit' antes de fazer predições.\")\n",
    "        \n",
    "        # Para cada um dos classificadores individuais do combinado\n",
    "        all_predictions = []\n",
    "        for estimator in self.estimators_:\n",
    "            try:\n",
    "                # Obter a classificação do exemplo usando o classificador individual\n",
    "                predictions = estimator.predict(X)\n",
    "                all_predictions.append(predictions)\n",
    "            except Exception as e:\n",
    "                # Em caso de erro, usa a classe mais frequente\n",
    "                predictions = np.full(X.shape[0], self.most_frequent_class_)\n",
    "                all_predictions.append(predictions)\n",
    "        \n",
    "        # Se não há predições válidas, retorna classe mais frequente\n",
    "        if len(all_predictions) == 0:\n",
    "            return np.full(X.shape[0], self.most_frequent_class_)\n",
    "        \n",
    "        # Transpõe para ter predições por amostra\n",
    "        all_predictions = np.array(all_predictions).T\n",
    "        \n",
    "        # Para cada exemplo, aplica votação majoritária\n",
    "        final_predictions = []\n",
    "        for sample_predictions in all_predictions:\n",
    "            # Contar quantas vezes cada classe foi selecionada\n",
    "            vote_counts = Counter(sample_predictions)\n",
    "            max_votes = max(vote_counts.values())\n",
    "            \n",
    "            # Obter a(s) mais votada(s)\n",
    "            most_voted_classes = [cls for cls, votes in vote_counts.items() \n",
    "                                if votes == max_votes]\n",
    "            \n",
    "            # Se mais de uma classe for a mais votada\n",
    "            if len(most_voted_classes) > 1:\n",
    "                # Retornar a classe mais frequente na base de treino dentre as que empataram\n",
    "                if self.most_frequent_class_ in most_voted_classes:\n",
    "                    final_predictions.append(self.most_frequent_class_)\n",
    "                else:\n",
    "                    # Se a classe mais frequente não está no empate, escolhe a primeira\n",
    "                    final_predictions.append(most_voted_classes[0])\n",
    "            else:\n",
    "                # Retornar a classe mais votada\n",
    "                final_predictions.append(most_voted_classes[0])\n",
    "        \n",
    "        return np.array(final_predictions)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Prediz probabilidades de classe para as amostras em X.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Amostras para predição.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        proba : ndarray of shape (n_samples, n_classes)\n",
    "            Probabilidades de cada classe para cada amostra.\n",
    "        \"\"\"\n",
    "        # Validação de entrada\n",
    "        X = check_array(X)\n",
    "        \n",
    "        # Verifica se o modelo foi treinado\n",
    "        if not hasattr(self, 'estimators_') or len(self.estimators_) == 0:\n",
    "            raise ValueError(\"Este modelo não foi treinado ainda. Chame 'fit' antes de fazer predições.\")\n",
    "        \n",
    "        # Obtém predições de todos os classificadores do ensemble\n",
    "        all_predictions = []\n",
    "        for estimator in self.estimators_:\n",
    "            try:\n",
    "                predictions = estimator.predict(X)\n",
    "                all_predictions.append(predictions)\n",
    "            except Exception as e:\n",
    "                # Em caso de erro, usa a classe mais frequente\n",
    "                predictions = np.full(X.shape[0], self.most_frequent_class_)\n",
    "                all_predictions.append(predictions)\n",
    "        \n",
    "        # Se não há predições válidas, retorna probabilidade 1 para classe mais frequente\n",
    "        if len(all_predictions) == 0:\n",
    "            probabilities = np.zeros((X.shape[0], self.n_classes_))\n",
    "            most_frequent_idx = np.where(self.classes_ == self.most_frequent_class_)[0][0]\n",
    "            probabilities[:, most_frequent_idx] = 1.0\n",
    "            return probabilities\n",
    "        \n",
    "        # Transpõe para ter predições por amostra\n",
    "        all_predictions = np.array(all_predictions).T\n",
    "        \n",
    "        # Calcula probabilidades baseadas na proporção de votos\n",
    "        probabilities = []\n",
    "        for sample_predictions in all_predictions:\n",
    "            vote_counts = Counter(sample_predictions)\n",
    "            total_votes = len(sample_predictions)\n",
    "            \n",
    "            # Cria vetor de probabilidades para todas as classes\n",
    "            sample_proba = np.zeros(self.n_classes_)\n",
    "            for i, cls in enumerate(self.classes_):\n",
    "                sample_proba[i] = vote_counts.get(cls, 0) / total_votes\n",
    "            \n",
    "            probabilities.append(sample_proba)\n",
    "        \n",
    "        return np.array(probabilities)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        Retorna a acurácia média nas amostras de teste dadas.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Amostras de teste.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Rótulos verdadeiros para X.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        score : float\n",
    "            Acurácia média de self.predict(X) em relação a y.\n",
    "        \"\"\"\n",
    "        predictions = self.predict(X)\n",
    "        return np.mean(predictions == y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c93dc2",
   "metadata": {},
   "source": [
    "---\n",
    "## Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "605bf399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a validação cruzada aninhada com Random Forest...\n",
      "Resultado usando 28 features pré-jogo e 2 classes.\n",
      "Grid de hiperparâmetros: 8 combinações\n",
      "\n",
      "RODADA 1/3\n",
      "----------------------------------------\n",
      "Fold Externo 1/10 - Acurácia: 0.6164 | Val.Interna: 0.6043\n",
      "Fold Externo 2/10 - Acurácia: 0.6042 | Val.Interna: 0.6140\n",
      "Fold Externo 3/10 - Acurácia: 0.6123 | Val.Interna: 0.6054\n",
      "Fold Externo 4/10 - Acurácia: 0.6380 | Val.Interna: 0.5938\n",
      "Fold Externo 5/10 - Acurácia: 0.5816 | Val.Interna: 0.6171\n",
      "Fold Externo 6/10 - Acurácia: 0.6221 | Val.Interna: 0.6116\n",
      "Fold Externo 7/10 - Acurácia: 0.6331 | Val.Interna: 0.6060\n",
      "Fold Externo 8/10 - Acurácia: 0.6049 | Val.Interna: 0.6136\n",
      "Fold Externo 9/10 - Acurácia: 0.6147 | Val.Interna: 0.6120\n",
      "Fold Externo 10/10 - Acurácia: 0.6025 | Val.Interna: 0.6092\n",
      "\n",
      "  Resultados da Rodada 1:\n",
      "     Acurácia Média: 0.6130 ± 0.0154\n",
      "     Min: 0.5816 | Max: 0.6380\n",
      "\n",
      "RODADA 2/3\n",
      "----------------------------------------\n",
      "Fold Externo 1/10 - Acurácia: 0.6127 | Val.Interna: 0.6080\n",
      "Fold Externo 2/10 - Acurácia: 0.5772 | Val.Interna: 0.6122\n",
      "Fold Externo 3/10 - Acurácia: 0.6233 | Val.Interna: 0.6038\n",
      "Fold Externo 4/10 - Acurácia: 0.5840 | Val.Interna: 0.6114\n",
      "Fold Externo 5/10 - Acurácia: 0.5951 | Val.Interna: 0.6135\n",
      "Fold Externo 6/10 - Acurácia: 0.6184 | Val.Interna: 0.6047\n",
      "Fold Externo 7/10 - Acurácia: 0.6160 | Val.Interna: 0.6088\n",
      "Fold Externo 8/10 - Acurácia: 0.6294 | Val.Interna: 0.6045\n",
      "Fold Externo 9/10 - Acurácia: 0.6233 | Val.Interna: 0.6122\n",
      "Fold Externo 10/10 - Acurácia: 0.6417 | Val.Interna: 0.6077\n",
      "\n",
      "  Resultados da Rodada 2:\n",
      "     Acurácia Média: 0.6121 ± 0.0194\n",
      "     Min: 0.5772 | Max: 0.6417\n",
      "\n",
      "RODADA 3/3\n",
      "----------------------------------------\n",
      "Fold Externo 1/10 - Acurácia: 0.6275 | Val.Interna: 0.6119\n",
      "Fold Externo 2/10 - Acurácia: 0.6385 | Val.Interna: 0.6138\n",
      "Fold Externo 3/10 - Acurácia: 0.6294 | Val.Interna: 0.6047\n",
      "Fold Externo 4/10 - Acurácia: 0.6405 | Val.Interna: 0.6042\n",
      "Fold Externo 5/10 - Acurácia: 0.6000 | Val.Interna: 0.6105\n",
      "Fold Externo 6/10 - Acurácia: 0.5681 | Val.Interna: 0.6188\n",
      "Fold Externo 7/10 - Acurácia: 0.6319 | Val.Interna: 0.6071\n",
      "Fold Externo 8/10 - Acurácia: 0.6147 | Val.Interna: 0.6152\n",
      "Fold Externo 9/10 - Acurácia: 0.6086 | Val.Interna: 0.6096\n",
      "Fold Externo 10/10 - Acurácia: 0.5963 | Val.Interna: 0.6079\n",
      "\n",
      "  Resultados da Rodada 3:\n",
      "     Acurácia Média: 0.6156 ± 0.0216\n",
      "     Min: 0.5681 | Max: 0.6405\n",
      "\n",
      "============================================================\n",
      "RESULTADO FINAL DAS 3 RODADAS\n",
      "============================================================\n",
      "Acurácia Final do Random Forest: 0.6136 ± 0.0015\n",
      "Intervalo de Confiança (~95%): [0.6106, 0.6165]\n"
     ]
    }
   ],
   "source": [
    "print(\"Iniciando a validação cruzada aninhada com Random Forest...\")\n",
    "\n",
    "print(f\"Resultado usando {len(PRE_GAME_FEATURES)} features pré-jogo e {n_classes} classes.\")\n",
    "resultados_rf_pre_jogo = nested_cv_random_forest(\n",
    "    df, \n",
    "    feature_columns=PRE_GAME_FEATURES, \n",
    "    target_column=TARGET, \n",
    "    n_classes=n_classes, \n",
    "    n_outer_folds=10, \n",
    "    n_inner_folds=4, \n",
    "    n_rounds=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8deb5517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a validação cruzada aninhada com KNN...\n",
      "Resultado usando 28 features pré-jogo e 2 classes.\n",
      "Grid de hiperparâmetros: 5 combinações\n",
      "Classificador: KNN\n",
      "\n",
      "RODADA 1/3\n",
      "----------------------------------------\n",
      "Fold Externo 1/10 - Acurácia: 0.5956 | Val.Interna: 0.5732\n",
      "Fold Externo 2/10 - Acurácia: 0.6140 | Val.Interna: 0.5736\n",
      "Fold Externo 3/10 - Acurácia: 0.5939 | Val.Interna: 0.5737\n",
      "Fold Externo 4/10 - Acurácia: 0.5706 | Val.Interna: 0.5731\n",
      "Fold Externo 5/10 - Acurácia: 0.5730 | Val.Interna: 0.5745\n",
      "Fold Externo 6/10 - Acurácia: 0.5742 | Val.Interna: 0.5700\n",
      "Fold Externo 7/10 - Acurácia: 0.5742 | Val.Interna: 0.5764\n",
      "Fold Externo 8/10 - Acurácia: 0.5681 | Val.Interna: 0.5756\n",
      "Fold Externo 9/10 - Acurácia: 0.5644 | Val.Interna: 0.5917\n",
      "Fold Externo 10/10 - Acurácia: 0.5926 | Val.Interna: 0.5768\n",
      "\n",
      "  Resultados da Rodada 1:\n",
      "     Acurácia Média: 0.5821 ± 0.0152\n",
      "     Min: 0.5644 | Max: 0.6140\n",
      "\n",
      "RODADA 2/3\n",
      "----------------------------------------\n",
      "Fold Externo 1/10 - Acurácia: 0.5625 | Val.Interna: 0.5792\n",
      "Fold Externo 2/10 - Acurácia: 0.5846 | Val.Interna: 0.5758\n",
      "Fold Externo 3/10 - Acurácia: 0.5816 | Val.Interna: 0.5767\n",
      "Fold Externo 4/10 - Acurácia: 0.5975 | Val.Interna: 0.5767\n",
      "Fold Externo 5/10 - Acurácia: 0.5755 | Val.Interna: 0.5763\n",
      "Fold Externo 6/10 - Acurácia: 0.5853 | Val.Interna: 0.5757\n",
      "Fold Externo 7/10 - Acurácia: 0.5767 | Val.Interna: 0.5806\n",
      "Fold Externo 8/10 - Acurácia: 0.5595 | Val.Interna: 0.5805\n",
      "Fold Externo 9/10 - Acurácia: 0.5742 | Val.Interna: 0.5734\n",
      "Fold Externo 10/10 - Acurácia: 0.5816 | Val.Interna: 0.5746\n",
      "\n",
      "  Resultados da Rodada 2:\n",
      "     Acurácia Média: 0.5779 ± 0.0105\n",
      "     Min: 0.5595 | Max: 0.5975\n",
      "\n",
      "RODADA 3/3\n",
      "----------------------------------------\n",
      "Fold Externo 1/10 - Acurácia: 0.5613 | Val.Interna: 0.5733\n",
      "Fold Externo 2/10 - Acurácia: 0.5723 | Val.Interna: 0.5748\n",
      "Fold Externo 3/10 - Acurácia: 0.5890 | Val.Interna: 0.5724\n",
      "Fold Externo 4/10 - Acurácia: 0.5791 | Val.Interna: 0.5723\n",
      "Fold Externo 5/10 - Acurácia: 0.5939 | Val.Interna: 0.5731\n",
      "Fold Externo 6/10 - Acurácia: 0.5730 | Val.Interna: 0.5832\n",
      "Fold Externo 7/10 - Acurácia: 0.5963 | Val.Interna: 0.5750\n",
      "Fold Externo 8/10 - Acurácia: 0.5853 | Val.Interna: 0.5738\n",
      "Fold Externo 9/10 - Acurácia: 0.5926 | Val.Interna: 0.5741\n",
      "Fold Externo 10/10 - Acurácia: 0.5804 | Val.Interna: 0.5738\n",
      "\n",
      "  Resultados da Rodada 3:\n",
      "     Acurácia Média: 0.5823 ± 0.0106\n",
      "     Min: 0.5613 | Max: 0.5963\n",
      "\n",
      "============================================================\n",
      "RESULTADO FINAL DAS 3 RODADAS\n",
      "============================================================\n",
      "Acurácia Final do KNN: 0.5808 ± 0.0020\n",
      "Intervalo de Confiança (~95%): [0.5767, 0.5848]\n"
     ]
    }
   ],
   "source": [
    "print(\"Iniciando a validação cruzada aninhada com KNN...\")\n",
    "print(f\"Resultado usando {len(PRE_GAME_FEATURES)} features pré-jogo e {n_classes} classes.\")\n",
    "\n",
    "knn_hyperparams = {'n_neighbors':[1,3,5,7,9]}\n",
    "\n",
    "resultados_knn_pre_jogo = nested_cv_classifier(\n",
    "    df=df,\n",
    "    feature_columns=PRE_GAME_FEATURES,\n",
    "    classifier=KNeighborsClassifier(n_jobs=-1),\n",
    "    classifier_name='KNN',\n",
    "    hyperparameters=knn_hyperparams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc606313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a validação cruzada aninhada com Decision Tree...\n",
      "Resultado usando 28 features pré-jogo e 2 classes.\n",
      "Grid de hiperparâmetros: 8 combinações\n",
      "Classificador: Decision Tree\n",
      "\n",
      "RODADA 1/3\n",
      "----------------------------------------\n",
      "Fold Externo 1/10 - Acurácia: 0.6152 | Val.Interna: 0.5915\n",
      "Fold Externo 2/10 - Acurácia: 0.5870 | Val.Interna: 0.5931\n",
      "Fold Externo 3/10 - Acurácia: 0.5791 | Val.Interna: 0.5857\n",
      "Fold Externo 4/10 - Acurácia: 0.5963 | Val.Interna: 0.5956\n",
      "Fold Externo 5/10 - Acurácia: 0.6037 | Val.Interna: 0.5966\n",
      "Fold Externo 6/10 - Acurácia: 0.5840 | Val.Interna: 0.5941\n",
      "Fold Externo 7/10 - Acurácia: 0.5730 | Val.Interna: 0.5889\n",
      "Fold Externo 8/10 - Acurácia: 0.6110 | Val.Interna: 0.5878\n",
      "Fold Externo 9/10 - Acurácia: 0.5963 | Val.Interna: 0.5959\n",
      "Fold Externo 10/10 - Acurácia: 0.5595 | Val.Interna: 0.5915\n",
      "\n",
      "  Resultados da Rodada 1:\n",
      "     Acurácia Média: 0.5905 ± 0.0165\n",
      "     Min: 0.5595 | Max: 0.6152\n",
      "\n",
      "RODADA 2/3\n",
      "----------------------------------------\n",
      "Fold Externo 1/10 - Acurácia: 0.5760 | Val.Interna: 0.5879\n",
      "Fold Externo 2/10 - Acurácia: 0.6189 | Val.Interna: 0.5898\n",
      "Fold Externo 3/10 - Acurácia: 0.6049 | Val.Interna: 0.5866\n",
      "Fold Externo 4/10 - Acurácia: 0.5840 | Val.Interna: 0.5934\n",
      "Fold Externo 5/10 - Acurácia: 0.5767 | Val.Interna: 0.6002\n",
      "Fold Externo 6/10 - Acurácia: 0.5877 | Val.Interna: 0.5921\n",
      "Fold Externo 7/10 - Acurácia: 0.5755 | Val.Interna: 0.5910\n",
      "Fold Externo 8/10 - Acurácia: 0.5951 | Val.Interna: 0.5859\n",
      "Fold Externo 9/10 - Acurácia: 0.5877 | Val.Interna: 0.5851\n",
      "Fold Externo 10/10 - Acurácia: 0.5779 | Val.Interna: 0.5869\n",
      "\n",
      "  Resultados da Rodada 2:\n",
      "     Acurácia Média: 0.5884 ± 0.0135\n",
      "     Min: 0.5755 | Max: 0.6189\n",
      "\n",
      "RODADA 3/3\n",
      "----------------------------------------\n",
      "Fold Externo 1/10 - Acurácia: 0.6091 | Val.Interna: 0.5901\n",
      "Fold Externo 2/10 - Acurácia: 0.5882 | Val.Interna: 0.5871\n",
      "Fold Externo 3/10 - Acurácia: 0.5914 | Val.Interna: 0.5873\n",
      "Fold Externo 4/10 - Acurácia: 0.6049 | Val.Interna: 0.5955\n",
      "Fold Externo 5/10 - Acurácia: 0.6012 | Val.Interna: 0.5876\n",
      "Fold Externo 6/10 - Acurácia: 0.5840 | Val.Interna: 0.5842\n",
      "Fold Externo 7/10 - Acurácia: 0.5644 | Val.Interna: 0.5911\n",
      "Fold Externo 8/10 - Acurácia: 0.5791 | Val.Interna: 0.5895\n",
      "Fold Externo 9/10 - Acurácia: 0.5890 | Val.Interna: 0.5891\n",
      "Fold Externo 10/10 - Acurácia: 0.5546 | Val.Interna: 0.5899\n",
      "\n",
      "  Resultados da Rodada 3:\n",
      "     Acurácia Média: 0.5866 ± 0.0163\n",
      "     Min: 0.5546 | Max: 0.6091\n",
      "\n",
      "============================================================\n",
      "RESULTADO FINAL DAS 3 RODADAS\n",
      "============================================================\n",
      "Acurácia Final do Decision Tree: 0.5885 ± 0.0016\n",
      "Intervalo de Confiança (~95%): [0.5853, 0.5917]\n"
     ]
    }
   ],
   "source": [
    "print(\"Iniciando a validação cruzada aninhada com Decision Tree...\")\n",
    "print(f\"Resultado usando {len(PRE_GAME_FEATURES)} features pré-jogo e {n_classes} classes.\")\n",
    "\n",
    "dt_hyperparams = {\n",
    "    'criterion': ['gini', 'entropy'], \n",
    "    'max_depth': [5, 10, 15, 25]\n",
    "}\n",
    "\n",
    "resultados_dt_pre_jogo = nested_cv_classifier(\n",
    "    df=df,\n",
    "    feature_columns=PRE_GAME_FEATURES,\n",
    "    classifier=DecisionTreeClassifier(random_state=36854321),\n",
    "    classifier_name='Decision Tree',\n",
    "    hyperparameters=dt_hyperparams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbf8afb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a validação cruzada aninhada com Multi Layer Perceptron...\n",
      "Resultado usando 28 features pré-jogo e 2 classes.\n",
      "Grid de hiperparâmetros: 8 combinações\n",
      "Classificador: Multi Layer Perceptron\n",
      "\n",
      "RODADA 1/3\n",
      "----------------------------------------\n",
      "Fold Externo 1/10 - Acurácia: 0.5490 | Val.Interna: 0.5802\n",
      "Fold Externo 2/10 - Acurácia: 0.5821 | Val.Interna: 0.5871\n",
      "Fold Externo 3/10 - Acurácia: 0.6086 | Val.Interna: 0.5899\n",
      "Fold Externo 4/10 - Acurácia: 0.5840 | Val.Interna: 0.5817\n",
      "Fold Externo 5/10 - Acurácia: 0.5914 | Val.Interna: 0.5858\n",
      "Fold Externo 6/10 - Acurácia: 0.5804 | Val.Interna: 0.5893\n",
      "Fold Externo 7/10 - Acurácia: 0.5877 | Val.Interna: 0.5898\n",
      "Fold Externo 8/10 - Acurácia: 0.6012 | Val.Interna: 0.5857\n",
      "Fold Externo 9/10 - Acurácia: 0.5816 | Val.Interna: 0.5865\n",
      "Fold Externo 10/10 - Acurácia: 0.5865 | Val.Interna: 0.5891\n",
      "\n",
      "  Resultados da Rodada 1:\n",
      "     Acurácia Média: 0.5853 ± 0.0149\n",
      "     Min: 0.5490 | Max: 0.6086\n",
      "\n",
      "RODADA 2/3\n",
      "----------------------------------------\n",
      "Fold Externo 1/10 - Acurácia: 0.5882 | Val.Interna: 0.5849\n",
      "Fold Externo 2/10 - Acurácia: 0.5907 | Val.Interna: 0.5780\n",
      "Fold Externo 3/10 - Acurácia: 0.5779 | Val.Interna: 0.5885\n",
      "Fold Externo 4/10 - Acurácia: 0.5890 | Val.Interna: 0.5798\n",
      "Fold Externo 5/10 - Acurácia: 0.5828 | Val.Interna: 0.5746\n",
      "Fold Externo 6/10 - Acurácia: 0.5926 | Val.Interna: 0.5867\n",
      "Fold Externo 7/10 - Acurácia: 0.6012 | Val.Interna: 0.5893\n",
      "Fold Externo 8/10 - Acurácia: 0.5742 | Val.Interna: 0.5863\n",
      "Fold Externo 9/10 - Acurácia: 0.5509 | Val.Interna: 0.5795\n",
      "Fold Externo 10/10 - Acurácia: 0.6098 | Val.Interna: 0.5829\n",
      "\n",
      "  Resultados da Rodada 2:\n",
      "     Acurácia Média: 0.5857 ± 0.0152\n",
      "     Min: 0.5509 | Max: 0.6098\n",
      "\n",
      "RODADA 3/3\n",
      "----------------------------------------\n",
      "Fold Externo 1/10 - Acurácia: 0.6213 | Val.Interna: 0.5757\n",
      "Fold Externo 2/10 - Acurácia: 0.6091 | Val.Interna: 0.5829\n",
      "Fold Externo 3/10 - Acurácia: 0.5632 | Val.Interna: 0.5872\n",
      "Fold Externo 4/10 - Acurácia: 0.6000 | Val.Interna: 0.5738\n",
      "Fold Externo 5/10 - Acurácia: 0.6135 | Val.Interna: 0.5902\n",
      "Fold Externo 6/10 - Acurácia: 0.5669 | Val.Interna: 0.5874\n",
      "Fold Externo 7/10 - Acurácia: 0.5914 | Val.Interna: 0.5820\n",
      "Fold Externo 8/10 - Acurácia: 0.5767 | Val.Interna: 0.5881\n",
      "Fold Externo 9/10 - Acurácia: 0.5509 | Val.Interna: 0.5853\n",
      "Fold Externo 10/10 - Acurácia: 0.5669 | Val.Interna: 0.5791\n",
      "\n",
      "  Resultados da Rodada 3:\n",
      "     Acurácia Média: 0.5860 ± 0.0231\n",
      "     Min: 0.5509 | Max: 0.6213\n",
      "\n",
      "============================================================\n",
      "RESULTADO FINAL DAS 3 RODADAS\n",
      "============================================================\n",
      "Acurácia Final do Multi Layer Perceptron: 0.5857 ± 0.0003\n",
      "Intervalo de Confiança (~95%): [0.5851, 0.5863]\n"
     ]
    }
   ],
   "source": [
    "print(\"Iniciando a validação cruzada aninhada com Multi Layer Perceptron...\")\n",
    "print(f\"Resultado usando {len(PRE_GAME_FEATURES)} features pré-jogo e {n_classes} classes.\")\n",
    "\n",
    "mlp_hyperparams = {\n",
    "    'hidden_layer_sizes': [(100,), (10,)],\n",
    "    'alpha': [0.0001, 0.005],\n",
    "    'learning_rate': ['constant', 'adaptive']\n",
    "}\n",
    "\n",
    "resultados_mlp_pre_jogo = nested_cv_classifier(\n",
    "    df=df,\n",
    "    feature_columns=PRE_GAME_FEATURES,\n",
    "    classifier=MLPClassifier(random_state=36854321, max_iter=1000),\n",
    "    classifier_name='Multi Layer Perceptron',\n",
    "    hyperparameters=mlp_hyperparams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1b211b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a validação cruzada aninhada com Heterogeneous Boosting Classifier...\n",
      "Resultado usando 28 features pré-jogo e 2 classes.\n",
      "Grid de hiperparâmetros: 5 combinações\n",
      "Classificador: Heterogeneous Boosting\n",
      "\n",
      "RODADA 1/3\n",
      "----------------------------------------\n",
      "Fold Externo 1/10 - Acurácia: 0.5772 | Val.Interna: 0.5706\n",
      "Fold Externo 2/10 - Acurácia: 0.5637 | Val.Interna: 0.5751\n",
      "Fold Externo 3/10 - Acurácia: 0.5730 | Val.Interna: 0.5741\n",
      "Fold Externo 4/10 - Acurácia: 0.5730 | Val.Interna: 0.5726\n",
      "Fold Externo 5/10 - Acurácia: 0.5865 | Val.Interna: 0.5783\n",
      "Fold Externo 6/10 - Acurácia: 0.5730 | Val.Interna: 0.5780\n",
      "Fold Externo 7/10 - Acurácia: 0.6012 | Val.Interna: 0.5734\n",
      "Fold Externo 8/10 - Acurácia: 0.5804 | Val.Interna: 0.5782\n",
      "Fold Externo 9/10 - Acurácia: 0.5730 | Val.Interna: 0.5654\n",
      "Fold Externo 10/10 - Acurácia: 0.5963 | Val.Interna: 0.5831\n",
      "\n",
      "  Resultados da Rodada 1:\n",
      "     Acurácia Média: 0.5797 ± 0.0111\n",
      "     Min: 0.5637 | Max: 0.6012\n",
      "\n",
      "RODADA 2/3\n",
      "----------------------------------------\n",
      "Fold Externo 1/10 - Acurácia: 0.5502 | Val.Interna: 0.5806\n",
      "Fold Externo 2/10 - Acurácia: 0.5797 | Val.Interna: 0.5789\n",
      "Fold Externo 3/10 - Acurácia: 0.5509 | Val.Interna: 0.5709\n",
      "Fold Externo 4/10 - Acurácia: 0.6098 | Val.Interna: 0.5769\n",
      "Fold Externo 5/10 - Acurácia: 0.5853 | Val.Interna: 0.5842\n",
      "Fold Externo 6/10 - Acurácia: 0.5865 | Val.Interna: 0.5806\n",
      "Fold Externo 7/10 - Acurácia: 0.6184 | Val.Interna: 0.5753\n",
      "Fold Externo 8/10 - Acurácia: 0.5951 | Val.Interna: 0.5801\n",
      "Fold Externo 9/10 - Acurácia: 0.5963 | Val.Interna: 0.5722\n",
      "Fold Externo 10/10 - Acurácia: 0.5730 | Val.Interna: 0.5735\n",
      "\n",
      "  Resultados da Rodada 2:\n",
      "     Acurácia Média: 0.5845 ± 0.0212\n",
      "     Min: 0.5502 | Max: 0.6184\n",
      "\n",
      "RODADA 3/3\n",
      "----------------------------------------\n",
      "Fold Externo 1/10 - Acurácia: 0.5502 | Val.Interna: 0.5806\n",
      "Fold Externo 2/10 - Acurácia: 0.5797 | Val.Interna: 0.5789\n",
      "Fold Externo 3/10 - Acurácia: 0.5509 | Val.Interna: 0.5709\n",
      "Fold Externo 4/10 - Acurácia: 0.6098 | Val.Interna: 0.5769\n",
      "Fold Externo 5/10 - Acurácia: 0.5853 | Val.Interna: 0.5842\n",
      "Fold Externo 6/10 - Acurácia: 0.5865 | Val.Interna: 0.5806\n",
      "Fold Externo 7/10 - Acurácia: 0.6184 | Val.Interna: 0.5753\n",
      "Fold Externo 8/10 - Acurácia: 0.5951 | Val.Interna: 0.5801\n",
      "Fold Externo 9/10 - Acurácia: 0.5963 | Val.Interna: 0.5722\n",
      "Fold Externo 10/10 - Acurácia: 0.5730 | Val.Interna: 0.5735\n",
      "\n",
      "  Resultados da Rodada 3:\n",
      "     Acurácia Média: 0.5845 ± 0.0212\n",
      "     Min: 0.5502 | Max: 0.6184\n",
      "\n",
      "============================================================\n",
      "RESULTADO FINAL DAS 3 RODADAS\n",
      "============================================================\n",
      "Acurácia Final do Heterogeneous Boosting: 0.5829 ± 0.0023\n",
      "Intervalo de Confiança (~95%): [0.5784, 0.5874]\n"
     ]
    }
   ],
   "source": [
    "print(\"Iniciando a validação cruzada aninhada com Heterogeneous Boosting Classifier...\")\n",
    "print(f\"Resultado usando {len(PRE_GAME_FEATURES)} features pré-jogo e {n_classes} classes.\")\n",
    "\n",
    "hb = HeterogeneousBoostingClassifier(n_estimators=5, random_state=36854321)\n",
    "hb_hyperparams = {'n_estimators': [5, 10, 15, 25, 50]}\n",
    "\n",
    "resultados_hb_pre_jogo = nested_cv_classifier(\n",
    "    df=df,\n",
    "    feature_columns=PRE_GAME_FEATURES,\n",
    "    classifier=hb,\n",
    "    classifier_name='Heterogeneous Boosting',\n",
    "    hyperparameters=hb_hyperparams,\n",
    "    target_column=TARGET,\n",
    "    n_classes=n_classes,\n",
    "    n_outer_folds=10,\n",
    "    n_inner_folds=4,\n",
    "    n_rounds=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be3f60b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hb_scores =  resultados_hb_pre_jogo['resultados_completos']['acuracia_media']\n",
    "dt_scores = resultados_dt_pre_jogo['resultados_completos']['acuracia_media']\n",
    "knn_scores = resultados_knn_pre_jogo['resultados_completos']['acuracia_media']\n",
    "mlp_scores = resultados_mlp_pre_jogo['resultados_completos']['acuracia_media']\n",
    "rf_scores = resultados_rf_pre_jogo['resultados_completos']['acuracia_media']\n",
    "\n",
    "# Resultados de cada classificador (exemplo com dicionário)\n",
    "results = {\n",
    "    'DT': dt_scores,\n",
    "    'KNN': knn_scores,\n",
    "    'MLP': mlp_scores,\n",
    "    'RF': rf_scores,\n",
    "    'HB': hb_scores\n",
    "}\n",
    "\n",
    "# Boxplot dos classificadores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=pd.DataFrame(results))\n",
    "plt.title(\"Boxplot das acurácias por classificador\")\n",
    "plt.ylabel(\"Acurácia\")\n",
    "plt.xlabel(\"Classificador\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32598d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Método   Média  Desvio Padrão  Limite Inferior  Limite Superior\n",
      "0     DT  0.5885         0.0020           0.5871           0.5899\n",
      "1    KNN  0.5808         0.0025           0.5790           0.5825\n",
      "2    MLP  0.5857         0.0004           0.5854           0.5859\n",
      "3     RF  0.6136         0.0018           0.6123           0.6148\n",
      "4     HB  0.5829         0.0028           0.5810           0.5849\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy.stats import t\n",
    "import numpy as np\n",
    "\n",
    "def compute_stats(scores_dict, n_folds):\n",
    "    summary = []\n",
    "    for method, scores in scores_dict.items():\n",
    "        mean = np.mean(scores)\n",
    "        std = np.std(scores, ddof=1)\n",
    "        ci = t.ppf(0.975, n_folds-1) * std / np.sqrt(n_folds)\n",
    "        summary.append([method, round(mean, 4), round(std, 4),\n",
    "                        round(mean - ci, 4), round(mean + ci, 4)])\n",
    "    return pd.DataFrame(summary, columns=[\"Método\", \"Média\", \"Desvio Padrão\", \"Limite Inferior\", \"Limite Superior\"])\n",
    "\n",
    "stats_table = compute_stats(results, n_folds=10)\n",
    "print(stats_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c4fb72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    DT 0.0674 0.2067 **0.0083**     0.2091\n",
      "0.2500    KNN 0.1027 **0.0012**     0.5424\n",
      "0.2500 0.2500    MLP **0.0015**     0.2318\n",
      "0.2500 0.2500 0.2500         RF **0.0038**\n",
      "0.2500 0.7500 0.2500     0.2500         HB\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from scipy.stats import t\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Função do teste t corrigido de Nadeau e Bengio\n",
    "def t_corrigido_nadeau_bengio(data1, data2, X, n_folds_externos):\n",
    "    N = len(X)\n",
    "    n = len(data1)\n",
    "    n_test = N // n_folds_externos\n",
    "    n_train = N - n_test\n",
    "    diffs = np.array(data1) - np.array(data2)\n",
    "    mean_diff = np.mean(diffs)\n",
    "    std_diff = np.std(diffs, ddof=1)\n",
    "    se_corrigido = std_diff * np.sqrt(1/n + n_test/n_train)\n",
    "    t_stat = mean_diff / se_corrigido\n",
    "    p_valor = 2 * (1 - t.cdf(abs(t_stat), df=n - 1))\n",
    "    return t_stat, p_valor\n",
    "\n",
    "# Preparar os dados\n",
    "metodos = list(results.keys())  # results = {'DT': [...], 'KNN': [...], ...}\n",
    "n_metodos = len(metodos)\n",
    "N = len(X)  # X precisa ser o conjunto de dados original\n",
    "n_folds_externos = 10\n",
    "\n",
    "# Inicializa matriz de p-valores\n",
    "matriz_p = np.empty((n_metodos, n_metodos), dtype=object)\n",
    "\n",
    "# Preenche a matriz com os testes\n",
    "for i in range(n_metodos):\n",
    "    for j in range(n_metodos):\n",
    "        if i == j:\n",
    "            matriz_p[i, j] = metodos[i]\n",
    "        elif i < j:\n",
    "            _, p = t_corrigido_nadeau_bengio(results[metodos[i]], results[metodos[j]], X, n_folds_externos)\n",
    "            matriz_p[i, j] = f\"**{p:.4f}**\" if p < 0.05 else f\"{p:.4f}\"\n",
    "        else:\n",
    "            _, p = stats.wilcoxon(results[metodos[i]], results[metodos[j]])\n",
    "            matriz_p[i, j] = f\"**{p:.4f}**\" if p < 0.05 else f\"{p:.4f}\"\n",
    "\n",
    "# Exibir a matriz formatada\n",
    "tabela_pvalues = pd.DataFrame(matriz_p, index=metodos, columns=metodos)\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(tabela_pvalues.to_string(index=False, header=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
