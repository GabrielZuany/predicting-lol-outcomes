{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2049733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import LabelEncoder\n",
    "from sklearn.base import defaultdict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59947c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>result</th>\n",
       "      <th>golddiffat15</th>\n",
       "      <th>xpdiffat15</th>\n",
       "      <th>csdiffat15</th>\n",
       "      <th>killsdiffat15</th>\n",
       "      <th>assistsdiffat15</th>\n",
       "      <th>golddiffat10</th>\n",
       "      <th>xpdiffat10</th>\n",
       "      <th>csdiffat10</th>\n",
       "      <th>...</th>\n",
       "      <th>OPP_EGR</th>\n",
       "      <th>OPP_MLR</th>\n",
       "      <th>OPP_FB%</th>\n",
       "      <th>OPP_FT%</th>\n",
       "      <th>OPP_F3T%</th>\n",
       "      <th>OPP_HLD%</th>\n",
       "      <th>OPP_DRG%</th>\n",
       "      <th>OPP_BN%</th>\n",
       "      <th>OPP_LNE%</th>\n",
       "      <th>OPP_JNG%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5018.0</td>\n",
       "      <td>4255.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1793.0</td>\n",
       "      <td>2365.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.1</td>\n",
       "      <td>-23.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>50</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>49.2</td>\n",
       "      <td>43.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>-1879.0</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>77.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>58</td>\n",
       "      <td>70</td>\n",
       "      <td>89</td>\n",
       "      <td>50.4</td>\n",
       "      <td>53.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>-579.0</td>\n",
       "      <td>-1643.0</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>77.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>58</td>\n",
       "      <td>70</td>\n",
       "      <td>89</td>\n",
       "      <td>50.4</td>\n",
       "      <td>53.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>3739.0</td>\n",
       "      <td>1118.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1746.0</td>\n",
       "      <td>824.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>63.9</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>48</td>\n",
       "      <td>60</td>\n",
       "      <td>48</td>\n",
       "      <td>51.6</td>\n",
       "      <td>50.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>-6390.0</td>\n",
       "      <td>-4569.0</td>\n",
       "      <td>-47.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-3500.0</td>\n",
       "      <td>-1882.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.8</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>49.7</td>\n",
       "      <td>42.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  result  golddiffat15  xpdiffat15  csdiffat15  killsdiffat15  \\\n",
       "0   10       1        5018.0      4255.0        86.0            5.0   \n",
       "1   22       0         573.0     -1879.0       -49.0            1.0   \n",
       "2   34       0        -579.0     -1643.0       -40.0           -1.0   \n",
       "3  106       1        3739.0      1118.0        53.0            1.0   \n",
       "4  118       0       -6390.0     -4569.0       -47.0          -10.0   \n",
       "\n",
       "   assistsdiffat15  golddiffat10  xpdiffat10  csdiffat10  ...  OPP_EGR  \\\n",
       "0              9.0        1793.0      2365.0        65.0  ...     23.1   \n",
       "1              4.0         759.0       171.0        -8.0  ...     77.2   \n",
       "2             -5.0          73.0        -1.0       -24.0  ...     77.2   \n",
       "3              0.0        1746.0       824.0        21.0  ...     63.9   \n",
       "4            -17.0       -3500.0     -1882.0       -18.0  ...     25.8   \n",
       "\n",
       "   OPP_MLR  OPP_FB%  OPP_FT%  OPP_F3T%  OPP_HLD%  OPP_DRG%  OPP_BN%  OPP_LNE%  \\\n",
       "0    -23.1        0        0        33        50        27        0      49.2   \n",
       "1     22.8      100      100       100        58        70       89      50.4   \n",
       "2     22.8      100      100       100        58        70       89      50.4   \n",
       "3     -3.9       67       67        67        48        60       48      51.6   \n",
       "4     -0.8       13       25        25        19        20       20      49.7   \n",
       "\n",
       "   OPP_JNG%  \n",
       "0      43.7  \n",
       "1      53.3  \n",
       "2      53.3  \n",
       "3      50.3  \n",
       "4      42.2  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = \"../data/jogosLoL2021.csv\"\n",
    "df = pd.read_csv(dataset_path, sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54924d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=\"id\", inplace=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1adfbd26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "      <th>golddiffat15</th>\n",
       "      <th>xpdiffat15</th>\n",
       "      <th>csdiffat15</th>\n",
       "      <th>killsdiffat15</th>\n",
       "      <th>assistsdiffat15</th>\n",
       "      <th>golddiffat10</th>\n",
       "      <th>xpdiffat10</th>\n",
       "      <th>csdiffat10</th>\n",
       "      <th>killsdiffat10</th>\n",
       "      <th>...</th>\n",
       "      <th>OPP_EGR</th>\n",
       "      <th>OPP_MLR</th>\n",
       "      <th>OPP_FB%</th>\n",
       "      <th>OPP_FT%</th>\n",
       "      <th>OPP_F3T%</th>\n",
       "      <th>OPP_HLD%</th>\n",
       "      <th>OPP_DRG%</th>\n",
       "      <th>OPP_BN%</th>\n",
       "      <th>OPP_LNE%</th>\n",
       "      <th>OPP_JNG%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "      <td>8152.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.531894</td>\n",
       "      <td>276.489328</td>\n",
       "      <td>4.800417</td>\n",
       "      <td>-0.348135</td>\n",
       "      <td>0.173332</td>\n",
       "      <td>0.311089</td>\n",
       "      <td>102.689892</td>\n",
       "      <td>32.706452</td>\n",
       "      <td>0.719946</td>\n",
       "      <td>0.090898</td>\n",
       "      <td>...</td>\n",
       "      <td>44.814009</td>\n",
       "      <td>-6.222031</td>\n",
       "      <td>48.298945</td>\n",
       "      <td>43.971663</td>\n",
       "      <td>42.174681</td>\n",
       "      <td>45.288027</td>\n",
       "      <td>45.828754</td>\n",
       "      <td>41.541830</td>\n",
       "      <td>49.774583</td>\n",
       "      <td>48.389561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499012</td>\n",
       "      <td>3092.939045</td>\n",
       "      <td>2164.253849</td>\n",
       "      <td>41.919732</td>\n",
       "      <td>3.769752</td>\n",
       "      <td>7.180593</td>\n",
       "      <td>1520.042590</td>\n",
       "      <td>1138.075319</td>\n",
       "      <td>27.248651</td>\n",
       "      <td>2.371612</td>\n",
       "      <td>...</td>\n",
       "      <td>14.794485</td>\n",
       "      <td>16.023668</td>\n",
       "      <td>20.784422</td>\n",
       "      <td>22.695632</td>\n",
       "      <td>24.110996</td>\n",
       "      <td>18.265473</td>\n",
       "      <td>13.370805</td>\n",
       "      <td>21.333411</td>\n",
       "      <td>1.044415</td>\n",
       "      <td>4.023629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-13908.000000</td>\n",
       "      <td>-10397.000000</td>\n",
       "      <td>-181.000000</td>\n",
       "      <td>-22.000000</td>\n",
       "      <td>-34.000000</td>\n",
       "      <td>-7632.000000</td>\n",
       "      <td>-5829.000000</td>\n",
       "      <td>-109.000000</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>-59.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.300000</td>\n",
       "      <td>35.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1685.250000</td>\n",
       "      <td>-1344.250000</td>\n",
       "      <td>-27.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-865.000000</td>\n",
       "      <td>-691.250000</td>\n",
       "      <td>-17.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>35.100000</td>\n",
       "      <td>-15.200000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>49.200000</td>\n",
       "      <td>45.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>313.500000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>44.800000</td>\n",
       "      <td>-5.900000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>49.700000</td>\n",
       "      <td>48.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2247.000000</td>\n",
       "      <td>1334.250000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1037.500000</td>\n",
       "      <td>754.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>53.400000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>50.300000</td>\n",
       "      <td>50.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>13855.000000</td>\n",
       "      <td>11914.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>7043.000000</td>\n",
       "      <td>6464.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>98.100000</td>\n",
       "      <td>49.400000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>55.300000</td>\n",
       "      <td>64.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            result  golddiffat15    xpdiffat15   csdiffat15  killsdiffat15  \\\n",
       "count  8152.000000   8152.000000   8152.000000  8152.000000    8152.000000   \n",
       "mean      0.531894    276.489328      4.800417    -0.348135       0.173332   \n",
       "std       0.499012   3092.939045   2164.253849    41.919732       3.769752   \n",
       "min       0.000000 -13908.000000 -10397.000000  -181.000000     -22.000000   \n",
       "25%       0.000000  -1685.250000  -1344.250000   -27.000000      -2.000000   \n",
       "50%       1.000000    313.500000     26.000000     0.000000       0.000000   \n",
       "75%       1.000000   2247.000000   1334.250000    26.000000       2.000000   \n",
       "max       1.000000  13855.000000  11914.000000   183.000000      21.000000   \n",
       "\n",
       "       assistsdiffat15  golddiffat10   xpdiffat10   csdiffat10  killsdiffat10  \\\n",
       "count      8152.000000   8152.000000  8152.000000  8152.000000    8152.000000   \n",
       "mean          0.311089    102.689892    32.706452     0.719946       0.090898   \n",
       "std           7.180593   1520.042590  1138.075319    27.248651       2.371612   \n",
       "min         -34.000000  -7632.000000 -5829.000000  -109.000000     -15.000000   \n",
       "25%          -4.000000   -865.000000  -691.250000   -17.000000      -1.000000   \n",
       "50%           0.000000    115.000000    26.000000     1.000000       0.000000   \n",
       "75%           4.000000   1037.500000   754.000000    19.000000       1.000000   \n",
       "max          32.000000   7043.000000  6464.000000   137.000000      13.000000   \n",
       "\n",
       "       ...      OPP_EGR      OPP_MLR      OPP_FB%      OPP_FT%     OPP_F3T%  \\\n",
       "count  ...  8152.000000  8152.000000  8152.000000  8152.000000  8152.000000   \n",
       "mean   ...    44.814009    -6.222031    48.298945    43.971663    42.174681   \n",
       "std    ...    14.794485    16.023668    20.784422    22.695632    24.110996   \n",
       "min    ...     3.100000   -59.900000     0.000000     0.000000     0.000000   \n",
       "25%    ...    35.100000   -15.200000    33.000000    30.000000    25.000000   \n",
       "50%    ...    44.800000    -5.900000    50.000000    43.000000    43.000000   \n",
       "75%    ...    53.400000     4.100000    61.000000    59.000000    58.000000   \n",
       "max    ...    98.100000    49.400000   100.000000   100.000000   100.000000   \n",
       "\n",
       "          OPP_HLD%     OPP_DRG%      OPP_BN%     OPP_LNE%     OPP_JNG%  \n",
       "count  8152.000000  8152.000000  8152.000000  8152.000000  8152.000000  \n",
       "mean     45.288027    45.828754    41.541830    49.774583    48.389561  \n",
       "std      18.265473    13.370805    21.333411     1.044415     4.023629  \n",
       "min       0.000000     0.000000     0.000000    45.300000    35.500000  \n",
       "25%      33.000000    39.000000    29.000000    49.200000    45.900000  \n",
       "50%      48.000000    46.000000    43.000000    49.700000    48.700000  \n",
       "75%      58.000000    54.000000    56.000000    50.300000    50.800000  \n",
       "max     100.000000    94.000000   100.000000    55.300000    64.800000  \n",
       "\n",
       "[8 rows x 39 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19bc189",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "DefiniÃ§Ã£o de seeds, variaveis, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92dcf3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "TARGET = \"result\"\n",
    "PRE_GAME_FEATURES = [\n",
    "    'WR', 'KD', 'GPR', 'GSPD', 'EGR', 'MLR', 'FB%', 'FT%', 'F3T%', \n",
    "    'HLD%', 'DRG%', 'BN%', 'LNE%', 'JNG%',\n",
    "    'OPP_WR', 'OPP_KD', 'OPP_GPR', 'OPP_GSPD', 'OPP_EGR', 'OPP_MLR',\n",
    "    'OPP_FB%', 'OPP_FT%', 'OPP_F3T%', 'OPP_HLD%', 'OPP_DRG%', \n",
    "    'OPP_BN%', 'OPP_LNE%', 'OPP_JNG%'\n",
    "]\n",
    "\n",
    "AT_10M_FEATURES = [\n",
    "    'golddiffat10',\n",
    "    'xpdiffat10',\n",
    "    'csdiffat10',   \n",
    "    'killsdiffat10',\n",
    "    'assistsdiffat10'\n",
    "]\n",
    "\n",
    "AT_15M_FEATURES = [\n",
    "    'golddiffat15', 'xpdiffat15', 'csdiffat15', \n",
    "    'killsdiffat15', 'assistsdiffat15'\n",
    "]\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "# Example: Move a tensor to the selected device\n",
    "# tensor = torch.tensor([1.0, 2.0, 3.0]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38fae145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se hÃ¡ colunas categÃ³ricas que precisam ser codificadas:\n",
    "feature_columns = None   \n",
    "le = LabelEncoder()\n",
    "\n",
    "# Separar features e target\n",
    "if feature_columns is None:\n",
    "    X = df.drop(columns=[TARGET]).values\n",
    "    feature_names = df.drop(columns=[TARGET]).columns.tolist()\n",
    "else:\n",
    "    X = df[feature_columns].values\n",
    "    feature_names = feature_columns\n",
    "\n",
    "y = df[TARGET].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70c27a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset carregado: 8152 amostras, 38 features, 2 classes\n",
      "DistribuiÃ§Ã£o das classes: {0: np.int64(3816), 1: np.int64(4336)}\n",
      "Features: ['golddiffat15', 'xpdiffat15', 'csdiffat15', 'killsdiffat15', 'assistsdiffat15']...\n"
     ]
    }
   ],
   "source": [
    "# InformaÃ§Ãµes do dataset\n",
    "n_samples, n_features = X.shape\n",
    "n_classes = len(np.unique(y))\n",
    "class_distribution = np.bincount(y)\n",
    "\n",
    "print(f\"Dataset carregado: {n_samples} amostras, {n_features} features, {n_classes} classes\")\n",
    "print(f\"DistribuiÃ§Ã£o das classes: {dict(zip(range(n_classes), class_distribution))}\")\n",
    "print(f\"Features: {feature_names[:5]}{'...' if len(feature_names) > 5 else ''}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267712f6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f197c085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cv_random_forest(\n",
    "    df, \n",
    "    feature_columns, \n",
    "    target_column='result', \n",
    "    rf_hyperparameters=None, \n",
    "    n_classes=2, \n",
    "    n_outer_folds=10, \n",
    "    n_inner_folds=4, \n",
    "    n_rounds=3, \n",
    "    random_state=36854321\n",
    "):\n",
    "    if rf_hyperparameters is None:\n",
    "        rf_hyperparameters = {'n_estimators': [5, 10, 15, 25], 'max_depth': [10, None]}\n",
    "    print(f\"Grid de hiperparÃ¢metros: {np.prod([len(v) for v in rf_hyperparameters.values()])} combinaÃ§Ãµes\")\n",
    "\n",
    "    X = df[feature_columns].values\n",
    "    y = df[target_column].values\n",
    "\n",
    "    resultados_completos = defaultdict(list)\n",
    "    detalhes_rodadas = []\n",
    "\n",
    "    for rodada in range(n_rounds):\n",
    "        print(f\"\\nRODADA {rodada + 1}/{n_rounds}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        indices = np.random.permutation(len(X))\n",
    "        X_shuffled = X[indices]\n",
    "        y_shuffled = y[indices]\n",
    "\n",
    "        outer_cv = StratifiedKFold(n_splits=n_outer_folds, shuffle=True, random_state=random_state)\n",
    "        acuracias_fold_externo = []\n",
    "        detalhes_folds = []\n",
    "\n",
    "        for fold_externo, (train_idx, test_idx) in enumerate(outer_cv.split(X_shuffled, y_shuffled)):\n",
    "            print(f\"Fold Externo {fold_externo + 1}/{n_outer_folds}\", end=\" - \")\n",
    "\n",
    "            X_train_outer = X_shuffled[train_idx]\n",
    "            X_test_outer = X_shuffled[test_idx]\n",
    "            y_train_outer = y_shuffled[train_idx]\n",
    "            y_test_outer = y_shuffled[test_idx]\n",
    "\n",
    "            train_dist = np.bincount(y_train_outer, minlength=n_classes)\n",
    "            test_dist = np.bincount(y_test_outer, minlength=n_classes)\n",
    "\n",
    "            inner_cv = StratifiedKFold(n_splits=n_inner_folds, shuffle=True, random_state=random_state)\n",
    "\n",
    "            rf = RandomForestClassifier(random_state=random_state, n_jobs=-1)\n",
    "            grid_search = GridSearchCV(\n",
    "                rf,\n",
    "                rf_hyperparameters,\n",
    "                cv=inner_cv,\n",
    "                scoring='accuracy',\n",
    "                n_jobs=-1,\n",
    "                verbose=0\n",
    "            ) # Otimiza hiperparÃ¢metros para cada fold externo e usa validaÃ§Ã£o cruzada interna (4 folds) -> perforance melhorada\n",
    "            \n",
    "            grid_search.fit(X_train_outer, y_train_outer)\n",
    "            y_pred = grid_search.predict(X_test_outer)\n",
    "            acuracia = accuracy_score(y_test_outer, y_pred)\n",
    "            acuracias_fold_externo.append(acuracia)\n",
    "\n",
    "            detalhes_fold = {\n",
    "                'fold': fold_externo + 1,\n",
    "                'melhores_params': grid_search.best_params_,\n",
    "                'acuracia_validacao_interna': grid_search.best_score_,\n",
    "                'acuracia_teste_externo': acuracia,\n",
    "                'tamanho_treino': len(X_train_outer),\n",
    "                'tamanho_teste': len(X_test_outer),\n",
    "                'distribuicao_treino': train_dist.tolist(),\n",
    "                'distribuicao_teste': test_dist.tolist()\n",
    "            }\n",
    "            detalhes_folds.append(detalhes_fold)\n",
    "\n",
    "            print(f\"AcurÃ¡cia: {acuracia:.4f} | Val.Interna: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "        acuracia_media_rodada = np.mean(acuracias_fold_externo)\n",
    "        desvio_rodada = np.std(acuracias_fold_externo)\n",
    "\n",
    "        print(f\"\\n  Resultados da Rodada {rodada + 1}:\")\n",
    "        print(f\"     AcurÃ¡cia MÃ©dia: {acuracia_media_rodada:.4f} Â± {desvio_rodada:.4f}\")\n",
    "        print(f\"     Min: {min(acuracias_fold_externo):.4f} | Max: {max(acuracias_fold_externo):.4f}\")\n",
    "\n",
    "        resultados_completos['rodada'].append(rodada + 1)\n",
    "        resultados_completos['acuracia_media'].append(acuracia_media_rodada)\n",
    "        resultados_completos['desvio_padrao'].append(desvio_rodada)\n",
    "        resultados_completos['acuracias_folds'].append(acuracias_fold_externo)\n",
    "\n",
    "        detalhes_rodadas.append({\n",
    "            'rodada': rodada + 1,\n",
    "            'acuracia_media': acuracia_media_rodada,\n",
    "            'desvio_padrao': desvio_rodada,\n",
    "            'detalhes_folds': detalhes_folds\n",
    "        })\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"RESULTADO FINAL DAS 3 RODADAS\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    acuracias_finais = resultados_completos['acuracia_media']\n",
    "    acuracia_final_media = np.mean(acuracias_finais)\n",
    "    desvio_final = np.std(acuracias_finais)\n",
    "\n",
    "    print(f\"AcurÃ¡cia Final do Random Forest: {acuracia_final_media:.4f} Â± {desvio_final:.4f}\")\n",
    "    print(f\"Intervalo de ConfianÃ§a (~95%): [{acuracia_final_media - 2*desvio_final:.4f}, {acuracia_final_media + 2*desvio_final:.4f}]\")\n",
    "\n",
    "    return {\n",
    "        'resultados_completos': resultados_completos,\n",
    "        'detalhes_rodadas': detalhes_rodadas,\n",
    "        'acuracia_final_media': acuracia_final_media,\n",
    "        'desvio_final': desvio_final\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee3980f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cv_classifier(\n",
    "    df, \n",
    "    feature_columns, \n",
    "    classifier,\n",
    "    classifier_name,\n",
    "    hyperparameters,\n",
    "    target_column='result', \n",
    "    n_classes=2, \n",
    "    n_outer_folds=10, \n",
    "    n_inner_folds=4, \n",
    "    n_rounds=3, \n",
    "    random_state=36854321\n",
    "):\n",
    "    \"\"\"\n",
    "    FunÃ§Ã£o genÃ©rica para validaÃ§Ã£o cruzada aninhada com qualquer classificador\n",
    "    \n",
    "    ParÃ¢metros:\n",
    "    - df: DataFrame com os dados\n",
    "    - feature_columns: lista das colunas de features\n",
    "    - classifier: instÃ¢ncia do classificador (ex: RandomForestClassifier(), MLPClassifier())\n",
    "    - classifier_name: nome do classificador para exibiÃ§Ã£o (ex: 'Random Forest', 'MLP', 'KNN')\n",
    "    - hyperparameters: dicionÃ¡rio com hiperparÃ¢metros do classificador\n",
    "    - target_column: nome da coluna target (padrÃ£o: 'result')\n",
    "    - n_classes: nÃºmero de classes (padrÃ£o: 2)\n",
    "    - n_outer_folds: nÃºmero de folds externos (padrÃ£o: 10)\n",
    "    - n_inner_folds: nÃºmero de folds internos (padrÃ£o: 4)\n",
    "    - n_rounds: nÃºmero de rodadas (padrÃ£o: 3)\n",
    "    - random_state: seed para reprodutibilidade\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Grid de hiperparÃ¢metros: {np.prod([len(v) for v in hyperparameters.values()])} combinaÃ§Ãµes\")\n",
    "    print(f\"Classificador: {classifier_name}\")\n",
    "\n",
    "    X = df[feature_columns].values\n",
    "    y = df[target_column].values\n",
    "\n",
    "    resultados_completos = defaultdict(list)\n",
    "    detalhes_rodadas = []\n",
    "\n",
    "    for rodada in range(n_rounds):\n",
    "        print(f\"\\nRODADA {rodada + 1}/{n_rounds}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        indices = np.random.permutation(len(X))\n",
    "        X_shuffled = X[indices]\n",
    "        y_shuffled = y[indices]\n",
    "\n",
    "        outer_cv = StratifiedKFold(n_splits=n_outer_folds, shuffle=True, random_state=random_state)\n",
    "        acuracias_fold_externo = []\n",
    "        detalhes_folds = []\n",
    "\n",
    "        for fold_externo, (train_idx, test_idx) in enumerate(outer_cv.split(X_shuffled, y_shuffled)):\n",
    "            print(f\"Fold Externo {fold_externo + 1}/{n_outer_folds}\", end=\" - \")\n",
    "\n",
    "            X_train_outer = X_shuffled[train_idx]\n",
    "            X_test_outer = X_shuffled[test_idx]\n",
    "            y_train_outer = y_shuffled[train_idx]\n",
    "            y_test_outer = y_shuffled[test_idx]\n",
    "\n",
    "            train_dist = np.bincount(y_train_outer, minlength=n_classes)\n",
    "            test_dist = np.bincount(y_test_outer, minlength=n_classes)\n",
    "\n",
    "            inner_cv = StratifiedKFold(n_splits=n_inner_folds, shuffle=True, random_state=random_state)\n",
    "\n",
    "            # Clona o classificador para cada fold para evitar problemas de estado\n",
    "            from sklearn.base import clone\n",
    "            clf = clone(classifier)\n",
    "            \n",
    "            grid_search = GridSearchCV(\n",
    "                clf,\n",
    "                hyperparameters,\n",
    "                cv=inner_cv,\n",
    "                scoring='accuracy',\n",
    "                n_jobs=-1,\n",
    "                verbose=0\n",
    "            ) # Otimiza hiperparÃ¢metros para cada fold externo e usa validaÃ§Ã£o cruzada interna (4 folds) -> performance melhorada\n",
    "            \n",
    "            grid_search.fit(X_train_outer, y_train_outer)\n",
    "            y_pred = grid_search.predict(X_test_outer)\n",
    "            acuracia = accuracy_score(y_test_outer, y_pred)\n",
    "            acuracias_fold_externo.append(acuracia)\n",
    "\n",
    "            detalhes_fold = {\n",
    "                'fold': fold_externo + 1,\n",
    "                'melhores_params': grid_search.best_params_,\n",
    "                'acuracia_validacao_interna': grid_search.best_score_,\n",
    "                'acuracia_teste_externo': acuracia,\n",
    "                'tamanho_treino': len(X_train_outer),\n",
    "                'tamanho_teste': len(X_test_outer),\n",
    "                'distribuicao_treino': train_dist.tolist(),\n",
    "                'distribuicao_teste': test_dist.tolist()\n",
    "            }\n",
    "            detalhes_folds.append(detalhes_fold)\n",
    "\n",
    "            print(f\"AcurÃ¡cia: {acuracia:.4f} | Val.Interna: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "        acuracia_media_rodada = np.mean(acuracias_fold_externo)\n",
    "        desvio_rodada = np.std(acuracias_fold_externo)\n",
    "\n",
    "        print(f\"\\n  Resultados da Rodada {rodada + 1}:\")\n",
    "        print(f\"     AcurÃ¡cia MÃ©dia: {acuracia_media_rodada:.4f} Â± {desvio_rodada:.4f}\")\n",
    "        print(f\"     Min: {min(acuracias_fold_externo):.4f} | Max: {max(acuracias_fold_externo):.4f}\")\n",
    "\n",
    "        resultados_completos['rodada'].append(rodada + 1)\n",
    "        resultados_completos['acuracia_media'].append(acuracia_media_rodada)\n",
    "        resultados_completos['desvio_padrao'].append(desvio_rodada)\n",
    "        resultados_completos['acuracias_folds'].append(acuracias_fold_externo)\n",
    "\n",
    "        detalhes_rodadas.append({\n",
    "            'rodada': rodada + 1,\n",
    "            'acuracia_media': acuracia_media_rodada,\n",
    "            'desvio_padrao': desvio_rodada,\n",
    "            'detalhes_folds': detalhes_folds\n",
    "        })\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"RESULTADO FINAL DAS 3 RODADAS\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    acuracias_finais = resultados_completos['acuracia_media']\n",
    "    acuracia_final_media = np.mean(acuracias_finais)\n",
    "    desvio_final = np.std(acuracias_finais)\n",
    "\n",
    "    print(f\"AcurÃ¡cia Final do {classifier_name}: {acuracia_final_media:.4f} Â± {desvio_final:.4f}\")\n",
    "    print(f\"Intervalo de ConfianÃ§a (~95%): [{acuracia_final_media - 2*desvio_final:.4f}, {acuracia_final_media + 2*desvio_final:.4f}]\")\n",
    "\n",
    "    return {\n",
    "        'resultados_completos': resultados_completos,\n",
    "        'detalhes_rodadas': detalhes_rodadas,\n",
    "        'acuracia_final_media': acuracia_final_media,\n",
    "        'desvio_final': desvio_final,\n",
    "        'classifier_name': classifier_name\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a662b8",
   "metadata": {},
   "source": [
    "---\n",
    "# HeterogeneousBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38721b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.utils.validation import check_X_y, check_array\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from collections import Counter\n",
    "import warnings\n",
    "\n",
    "class HeterogeneousBoostingClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    Heterogeneous Boosting Classifier\n",
    "    \n",
    "    Um classificador ensemble que combina diferentes tipos de classificadores base\n",
    "    (Decision Tree, Naive Bayes, MLP, KNN) usando boosting com votaÃ§Ã£o majoritÃ¡ria.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_estimators : int, default=10\n",
    "        NÃºmero de classificadores base que comporÃ£o o ensemble.\n",
    "    \n",
    "    random_state : int, RandomState instance or None, default=None\n",
    "        Controla a aleatoriedade da seleÃ§Ã£o de exemplos com reposiÃ§Ã£o.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    classes_ : ndarray of shape (n_classes,)\n",
    "        As classes Ãºnicas encontradas durante o ajuste.\n",
    "    \n",
    "    n_classes_ : int\n",
    "        NÃºmero de classes.\n",
    "    \n",
    "    most_frequent_class_ : class label\n",
    "        A classe mais frequente na base de treino.\n",
    "    \n",
    "    estimators_ : list\n",
    "        Lista dos classificadores selecionados para o ensemble.\n",
    "    \n",
    "    X_train_ : ndarray\n",
    "        Dados de treino originais armazenados para referÃªncia.\n",
    "    \n",
    "    y_train_ : ndarray\n",
    "        RÃ³tulos de treino originais armazenados para referÃªncia.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_estimators=10, random_state=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def _create_base_classifiers(self):\n",
    "        \"\"\"Cria os classificadores base com parÃ¢metros default do sklearn\"\"\"\n",
    "        return {\n",
    "            'NB': GaussianNB(),\n",
    "            'DT': DecisionTreeClassifier(random_state=self.random_state),\n",
    "            'MLP': MLPClassifier(random_state=self.random_state, max_iter=1000),\n",
    "            'KNN': KNeighborsClassifier()\n",
    "        }\n",
    "    \n",
    "    def _roulette_wheel_selection(self, X, y, weights):\n",
    "        \"\"\"\n",
    "        Seleciona exemplos com reposiÃ§Ã£o usando o mÃ©todo da roleta\n",
    "        baseado nos pesos dos exemplos.\n",
    "        \"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        \n",
    "        # Verifica se hÃ¡ pesos invÃ¡lidos (NaN, inf, ou negativos)\n",
    "        if np.any(np.isnan(weights)) or np.any(np.isinf(weights)) or np.any(weights < 0):\n",
    "            # Se hÃ¡ pesos invÃ¡lidos, reinicia com pesos uniformes\n",
    "            weights = np.ones(n_samples, dtype=float)\n",
    "        \n",
    "        # Verifica se todos os pesos sÃ£o zero\n",
    "        if np.sum(weights) == 0:\n",
    "            weights = np.ones(n_samples, dtype=float)\n",
    "        \n",
    "        # Normaliza os pesos para que somem 1\n",
    "        normalized_weights = weights / np.sum(weights)\n",
    "        \n",
    "        # Verifica novamente se a normalizaÃ§Ã£o gerou NaN\n",
    "        if np.any(np.isnan(normalized_weights)):\n",
    "            normalized_weights = np.ones(n_samples, dtype=float) / n_samples\n",
    "        \n",
    "        # Seleciona Ã­ndices com base nos pesos (com reposiÃ§Ã£o)\n",
    "        selected_indices = np.random.choice(\n",
    "            n_samples, \n",
    "            size=n_samples, \n",
    "            replace=True, \n",
    "            p=normalized_weights\n",
    "        )\n",
    "        \n",
    "        return X[selected_indices], y[selected_indices], selected_indices\n",
    "    \n",
    "    def _evaluate_classifier(self, classifier, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Treina e avalia o desempenho de um classificador nos dados de treino\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "                warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "                # Treina o classificador\n",
    "                classifier.fit(X_train, y_train)\n",
    "                # Testa no mesmo conjunto (conforme pseudocÃ³digo)\n",
    "                predictions = classifier.predict(X_train)\n",
    "                # Calcula acurÃ¡cia\n",
    "                accuracy = np.mean(predictions == y_train)\n",
    "                return accuracy, predictions, classifier\n",
    "        except Exception as e:\n",
    "            # Em caso de erro, retorna acurÃ¡cia 0\n",
    "            print(f\"Erro ao treinar classificador: {e}\")\n",
    "            return 0.0, np.full(len(y_train), y_train[0]), classifier\n",
    "    \n",
    "    def _select_best_classifier(self, results):\n",
    "        \"\"\"\n",
    "        Seleciona o melhor classificador baseado na acurÃ¡cia.\n",
    "        Em caso de empate, usa a preferÃªncia: MLP, DT, KNN, NB\n",
    "        \"\"\"\n",
    "        preference_order = ['MLP', 'DT', 'KNN', 'NB']\n",
    "        \n",
    "        # Encontra a melhor acurÃ¡cia\n",
    "        max_accuracy = max(acc for acc, _, _, _ in results.values())\n",
    "        \n",
    "        # Encontra classificadores com melhor acurÃ¡cia\n",
    "        best_classifiers = [name for name, (acc, _, _, _) in results.items() \n",
    "                          if acc == max_accuracy]\n",
    "        \n",
    "        # Aplica ordem de preferÃªncia em caso de empate\n",
    "        for preferred in preference_order:\n",
    "            if preferred in best_classifiers:\n",
    "                return preferred, results[preferred]\n",
    "        \n",
    "        # Fallback (nÃ£o deveria acontecer)\n",
    "        return list(best_classifiers)[0], results[list(best_classifiers)[0]]\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Ajusta o classificador Heterogeneous Boosting.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Dados de treino.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            RÃ³tulos de treino.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Retorna self.\n",
    "        \"\"\"\n",
    "        # ValidaÃ§Ã£o de entrada\n",
    "        X, y = check_X_y(X, y)\n",
    "        \n",
    "        # Armazena dados de treino originais\n",
    "        self.X_train_ = X.copy()\n",
    "        self.y_train_ = y.copy()\n",
    "        \n",
    "        # Armazena classes Ãºnicas\n",
    "        self.classes_ = unique_labels(y)\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "        \n",
    "        # Encontra e guarda a classe mais frequente\n",
    "        class_counts = Counter(y)\n",
    "        self.most_frequent_class_ = class_counts.most_common(1)[0][0]\n",
    "        \n",
    "        # Inicializa pesos dos exemplos com valor 1 para todos\n",
    "        weights = np.ones(X.shape[0], dtype=float)\n",
    "        \n",
    "        # Inicializa lista de classificadores do ensemble\n",
    "        self.estimators_ = []\n",
    "        \n",
    "        # Configura random state para reprodutibilidade\n",
    "        if self.random_state is not None:\n",
    "            np.random.seed(self.random_state)\n",
    "        \n",
    "        # Repete n_estimators vezes\n",
    "        for iteration in range(self.n_estimators):\n",
    "            # CORREÃ‡ÃƒO: Primeiro classificador usa base original, demais usam seleÃ§Ã£o com roleta\n",
    "            if iteration == 0:\n",
    "                # Primeiro classificador: usa base de treino original\n",
    "                X_train_iter = X\n",
    "                y_train_iter = y\n",
    "                selected_indices = np.arange(len(y))\n",
    "            else:\n",
    "                # Demais classificadores: usa seleÃ§Ã£o com mÃ©todo da roleta\n",
    "                X_train_iter, y_train_iter, selected_indices = self._roulette_wheel_selection(X, y, weights)\n",
    "            \n",
    "            # Para cada um dos mÃ©todos de classificaÃ§Ã£o (NB, DT, MLP, KNN)\n",
    "            base_classifiers = self._create_base_classifiers()\n",
    "            results = {}\n",
    "            \n",
    "            for name, classifier in base_classifiers.items():\n",
    "                # Treina e testa o classificador nos exemplos selecionados\n",
    "                accuracy, predictions, trained_classifier = self._evaluate_classifier(\n",
    "                    classifier, X_train_iter, y_train_iter\n",
    "                )\n",
    "                results[name] = (accuracy, predictions, trained_classifier, selected_indices)\n",
    "            \n",
    "            # Escolhe o classificador com melhor desempenho\n",
    "            best_name, (best_accuracy, best_predictions, best_classifier, best_indices) = \\\n",
    "                self._select_best_classifier(results)\n",
    "            \n",
    "            # Adiciona o melhor classificador ao combinado\n",
    "            self.estimators_.append(best_classifier)\n",
    "            \n",
    "            # Dobra o peso dos exemplos classificados de forma errÃ´nea\n",
    "            # CORREÃ‡ÃƒO: Para o primeiro classificador, usar Ã­ndices diretos\n",
    "            if iteration == 0:\n",
    "                # Primeiro classificador: atualiza pesos baseado na prediÃ§Ã£o na base original\n",
    "                for i in range(len(y)):\n",
    "                    if best_predictions[i] != y[i]:\n",
    "                        weights[i] *= 2.0\n",
    "            else:\n",
    "                # Demais classificadores: atualiza pesos dos exemplos originais correspondentes\n",
    "                for i, original_idx in enumerate(best_indices):\n",
    "                    if best_predictions[i] != y_train_iter[i]:\n",
    "                        weights[original_idx] *= 2.0\n",
    "            \n",
    "            # Verifica se os pesos se tornaram muito grandes (overflow protection)\n",
    "            if np.any(weights > 1e10):\n",
    "                weights = weights / np.max(weights) * 1000\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Prediz classes para as amostras em X usando votaÃ§Ã£o majoritÃ¡ria.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Amostras para prediÃ§Ã£o.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        y_pred : ndarray of shape (n_samples,)\n",
    "            Classes preditas.\n",
    "        \"\"\"\n",
    "        # ValidaÃ§Ã£o de entrada\n",
    "        X = check_array(X)\n",
    "        \n",
    "        # Verifica se o modelo foi treinado\n",
    "        if not hasattr(self, 'estimators_') or len(self.estimators_) == 0:\n",
    "            raise ValueError(\"Este modelo nÃ£o foi treinado ainda. Chame 'fit' antes de fazer prediÃ§Ãµes.\")\n",
    "        \n",
    "        # Para cada um dos classificadores individuais do combinado\n",
    "        all_predictions = []\n",
    "        for estimator in self.estimators_:\n",
    "            try:\n",
    "                # Obter a classificaÃ§Ã£o do exemplo usando o classificador individual\n",
    "                predictions = estimator.predict(X)\n",
    "                all_predictions.append(predictions)\n",
    "            except Exception as e:\n",
    "                # Em caso de erro, usa a classe mais frequente\n",
    "                predictions = np.full(X.shape[0], self.most_frequent_class_)\n",
    "                all_predictions.append(predictions)\n",
    "        \n",
    "        # Se nÃ£o hÃ¡ prediÃ§Ãµes vÃ¡lidas, retorna classe mais frequente\n",
    "        if len(all_predictions) == 0:\n",
    "            return np.full(X.shape[0], self.most_frequent_class_)\n",
    "        \n",
    "        # TranspÃµe para ter prediÃ§Ãµes por amostra\n",
    "        all_predictions = np.array(all_predictions).T\n",
    "        \n",
    "        # Para cada exemplo, aplica votaÃ§Ã£o majoritÃ¡ria\n",
    "        final_predictions = []\n",
    "        for sample_predictions in all_predictions:\n",
    "            # Contar quantas vezes cada classe foi selecionada\n",
    "            vote_counts = Counter(sample_predictions)\n",
    "            max_votes = max(vote_counts.values())\n",
    "            \n",
    "            # Obter a(s) mais votada(s)\n",
    "            most_voted_classes = [cls for cls, votes in vote_counts.items() \n",
    "                                if votes == max_votes]\n",
    "            \n",
    "            # Se mais de uma classe for a mais votada\n",
    "            if len(most_voted_classes) > 1:\n",
    "                # Retornar a classe mais frequente na base de treino dentre as que empataram\n",
    "                if self.most_frequent_class_ in most_voted_classes:\n",
    "                    final_predictions.append(self.most_frequent_class_)\n",
    "                else:\n",
    "                    # Se a classe mais frequente nÃ£o estÃ¡ no empate, escolhe a primeira\n",
    "                    final_predictions.append(most_voted_classes[0])\n",
    "            else:\n",
    "                # Retornar a classe mais votada\n",
    "                final_predictions.append(most_voted_classes[0])\n",
    "        \n",
    "        return np.array(final_predictions)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Prediz probabilidades de classe para as amostras em X.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Amostras para prediÃ§Ã£o.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        proba : ndarray of shape (n_samples, n_classes)\n",
    "            Probabilidades de cada classe para cada amostra.\n",
    "        \"\"\"\n",
    "        # ValidaÃ§Ã£o de entrada\n",
    "        X = check_array(X)\n",
    "        \n",
    "        # Verifica se o modelo foi treinado\n",
    "        if not hasattr(self, 'estimators_') or len(self.estimators_) == 0:\n",
    "            raise ValueError(\"Este modelo nÃ£o foi treinado ainda. Chame 'fit' antes de fazer prediÃ§Ãµes.\")\n",
    "        \n",
    "        # ObtÃ©m prediÃ§Ãµes de todos os classificadores do ensemble\n",
    "        all_predictions = []\n",
    "        for estimator in self.estimators_:\n",
    "            try:\n",
    "                predictions = estimator.predict(X)\n",
    "                all_predictions.append(predictions)\n",
    "            except Exception as e:\n",
    "                # Em caso de erro, usa a classe mais frequente\n",
    "                predictions = np.full(X.shape[0], self.most_frequent_class_)\n",
    "                all_predictions.append(predictions)\n",
    "        \n",
    "        # Se nÃ£o hÃ¡ prediÃ§Ãµes vÃ¡lidas, retorna probabilidade 1 para classe mais frequente\n",
    "        if len(all_predictions) == 0:\n",
    "            probabilities = np.zeros((X.shape[0], self.n_classes_))\n",
    "            most_frequent_idx = np.where(self.classes_ == self.most_frequent_class_)[0][0]\n",
    "            probabilities[:, most_frequent_idx] = 1.0\n",
    "            return probabilities\n",
    "        \n",
    "        # TranspÃµe para ter prediÃ§Ãµes por amostra\n",
    "        all_predictions = np.array(all_predictions).T\n",
    "        \n",
    "        # Calcula probabilidades baseadas na proporÃ§Ã£o de votos\n",
    "        probabilities = []\n",
    "        for sample_predictions in all_predictions:\n",
    "            vote_counts = Counter(sample_predictions)\n",
    "            total_votes = len(sample_predictions)\n",
    "            \n",
    "            # Cria vetor de probabilidades para todas as classes\n",
    "            sample_proba = np.zeros(self.n_classes_)\n",
    "            for i, cls in enumerate(self.classes_):\n",
    "                sample_proba[i] = vote_counts.get(cls, 0) / total_votes\n",
    "            \n",
    "            probabilities.append(sample_proba)\n",
    "        \n",
    "        return np.array(probabilities)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        Retorna a acurÃ¡cia mÃ©dia nas amostras de teste dadas.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Amostras de teste.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            RÃ³tulos verdadeiros para X.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        score : float\n",
    "            AcurÃ¡cia mÃ©dia de self.predict(X) em relaÃ§Ã£o a y.\n",
    "        \"\"\"\n",
    "        predictions = self.predict(X)\n",
    "        return np.mean(predictions == y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c93dc2",
   "metadata": {},
   "source": [
    "---\n",
    "## ExecuÃ§Ã£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "605bf399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a validaÃ§Ã£o cruzada aninhada com Random Forest...\n",
      "Resultado usando 28 features prÃ©-jogo e 2 classes.\n",
      "Grid de hiperparÃ¢metros: 8 combinaÃ§Ãµes\n",
      "\n",
      "RODADA 1/3\n",
      "----------------------------------------\n",
      "Fold Externo 1/10 - AcurÃ¡cia: 0.6164 | Val.Interna: 0.6043\n",
      "Fold Externo 2/10 - AcurÃ¡cia: 0.6042 | Val.Interna: 0.6140\n",
      "Fold Externo 3/10 - AcurÃ¡cia: 0.6123 | Val.Interna: 0.6054\n",
      "Fold Externo 4/10 - AcurÃ¡cia: 0.6380 | Val.Interna: 0.5938\n",
      "Fold Externo 5/10 - AcurÃ¡cia: 0.5816 | Val.Interna: 0.6171\n",
      "Fold Externo 6/10 - AcurÃ¡cia: 0.6221 | Val.Interna: 0.6116\n",
      "Fold Externo 7/10 - AcurÃ¡cia: 0.6331 | Val.Interna: 0.6060\n",
      "Fold Externo 8/10 - AcurÃ¡cia: 0.6049 | Val.Interna: 0.6136\n",
      "Fold Externo 9/10 - AcurÃ¡cia: 0.6147 | Val.Interna: 0.6120\n",
      "Fold Externo 10/10 - AcurÃ¡cia: 0.6025 | Val.Interna: 0.6092\n",
      "\n",
      "  Resultados da Rodada 1:\n",
      "     AcurÃ¡cia MÃ©dia: 0.6130 Â± 0.0154\n",
      "     Min: 0.5816 | Max: 0.6380\n",
      "\n",
      "RODADA 2/3\n",
      "----------------------------------------\n",
      "Fold Externo 1/10 - AcurÃ¡cia: 0.6127 | Val.Interna: 0.6080\n",
      "Fold Externo 2/10 - AcurÃ¡cia: 0.5772 | Val.Interna: 0.6122\n",
      "Fold Externo 3/10 - AcurÃ¡cia: 0.6233 | Val.Interna: 0.6038\n",
      "Fold Externo 4/10 - AcurÃ¡cia: 0.5840 | Val.Interna: 0.6114\n",
      "Fold Externo 5/10 - AcurÃ¡cia: 0.5951 | Val.Interna: 0.6135\n",
      "Fold Externo 6/10 - AcurÃ¡cia: 0.6184 | Val.Interna: 0.6047\n",
      "Fold Externo 7/10 - AcurÃ¡cia: 0.6160 | Val.Interna: 0.6088\n",
      "Fold Externo 8/10 - AcurÃ¡cia: 0.6294 | Val.Interna: 0.6045\n",
      "Fold Externo 9/10 - AcurÃ¡cia: 0.6233 | Val.Interna: 0.6122\n",
      "Fold Externo 10/10 - AcurÃ¡cia: 0.6417 | Val.Interna: 0.6077\n",
      "\n",
      "  Resultados da Rodada 2:\n",
      "     AcurÃ¡cia MÃ©dia: 0.6121 Â± 0.0194\n",
      "     Min: 0.5772 | Max: 0.6417\n",
      "\n",
      "RODADA 3/3\n",
      "----------------------------------------\n",
      "Fold Externo 1/10 - AcurÃ¡cia: 0.6275 | Val.Interna: 0.6119\n",
      "Fold Externo 2/10 - AcurÃ¡cia: 0.6385 | Val.Interna: 0.6138\n",
      "Fold Externo 3/10 - AcurÃ¡cia: 0.6294 | Val.Interna: 0.6047\n",
      "Fold Externo 4/10 - AcurÃ¡cia: 0.6405 | Val.Interna: 0.6042\n",
      "Fold Externo 5/10 - AcurÃ¡cia: 0.6000 | Val.Interna: 0.6105\n",
      "Fold Externo 6/10 - AcurÃ¡cia: 0.5681 | Val.Interna: 0.6188\n",
      "Fold Externo 7/10 - AcurÃ¡cia: 0.6319 | Val.Interna: 0.6071\n",
      "Fold Externo 8/10 - AcurÃ¡cia: 0.6147 | Val.Interna: 0.6152\n",
      "Fold Externo 9/10 - AcurÃ¡cia: 0.6086 | Val.Interna: 0.6096\n",
      "Fold Externo 10/10 - AcurÃ¡cia: 0.5963 | Val.Interna: 0.6079\n",
      "\n",
      "  Resultados da Rodada 3:\n",
      "     AcurÃ¡cia MÃ©dia: 0.6156 Â± 0.0216\n",
      "     Min: 0.5681 | Max: 0.6405\n",
      "\n",
      "============================================================\n",
      "RESULTADO FINAL DAS 3 RODADAS\n",
      "============================================================\n",
      "AcurÃ¡cia Final do Random Forest: 0.6136 Â± 0.0015\n",
      "Intervalo de ConfianÃ§a (~95%): [0.6106, 0.6165]\n"
     ]
    }
   ],
   "source": [
    "print(\"Iniciando a validaÃ§Ã£o cruzada aninhada com Random Forest...\")\n",
    "\n",
    "print(f\"Resultado usando {len(PRE_GAME_FEATURES)} features prÃ©-jogo e {n_classes} classes.\")\n",
    "resultados_rf_pre_jogo = nested_cv_random_forest(\n",
    "    df, \n",
    "    feature_columns=PRE_GAME_FEATURES, \n",
    "    target_column=TARGET, \n",
    "    n_classes=n_classes, \n",
    "    n_outer_folds=10, \n",
    "    n_inner_folds=4, \n",
    "    n_rounds=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8deb5517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a validaÃ§Ã£o cruzada aninhada com KNN...\n",
      "Resultado usando 28 features prÃ©-jogo e 2 classes.\n",
      "Grid de hiperparÃ¢metros: 5 combinaÃ§Ãµes\n",
      "Classificador: KNN\n",
      "\n",
      "RODADA 1/3\n",
      "----------------------------------------\n",
      "Fold Externo 1/10 - AcurÃ¡cia: 0.5956 | Val.Interna: 0.5732\n",
      "Fold Externo 2/10 - AcurÃ¡cia: 0.6140 | Val.Interna: 0.5736\n",
      "Fold Externo 3/10 - AcurÃ¡cia: 0.5939 | Val.Interna: 0.5737\n",
      "Fold Externo 4/10 - AcurÃ¡cia: 0.5706 | Val.Interna: 0.5731\n",
      "Fold Externo 5/10 - AcurÃ¡cia: 0.5730 | Val.Interna: 0.5745\n",
      "Fold Externo 6/10 - AcurÃ¡cia: 0.5742 | Val.Interna: 0.5700\n",
      "Fold Externo 7/10 - AcurÃ¡cia: 0.5742 | Val.Interna: 0.5764\n",
      "Fold Externo 8/10 - AcurÃ¡cia: 0.5681 | Val.Interna: 0.5756\n",
      "Fold Externo 9/10 - AcurÃ¡cia: 0.5644 | Val.Interna: 0.5917\n",
      "Fold Externo 10/10 - AcurÃ¡cia: 0.5926 | Val.Interna: 0.5768\n",
      "\n",
      "  Resultados da Rodada 1:\n",
      "     AcurÃ¡cia MÃ©dia: 0.5821 Â± 0.0152\n",
      "     Min: 0.5644 | Max: 0.6140\n",
      "\n",
      "RODADA 2/3\n",
      "----------------------------------------\n",
      "Fold Externo 1/10 - AcurÃ¡cia: 0.5625 | Val.Interna: 0.5792\n",
      "Fold Externo 2/10 - AcurÃ¡cia: 0.5846 | Val.Interna: 0.5758\n",
      "Fold Externo 3/10 - AcurÃ¡cia: 0.5816 | Val.Interna: 0.5767\n",
      "Fold Externo 4/10 - AcurÃ¡cia: 0.5975 | Val.Interna: 0.5767\n",
      "Fold Externo 5/10 - AcurÃ¡cia: 0.5755 | Val.Interna: 0.5763\n",
      "Fold Externo 6/10 - AcurÃ¡cia: 0.5853 | Val.Interna: 0.5757\n",
      "Fold Externo 7/10 - AcurÃ¡cia: 0.5767 | Val.Interna: 0.5806\n",
      "Fold Externo 8/10 - AcurÃ¡cia: 0.5595 | Val.Interna: 0.5805\n",
      "Fold Externo 9/10 - AcurÃ¡cia: 0.5742 | Val.Interna: 0.5734\n",
      "Fold Externo 10/10 - AcurÃ¡cia: 0.5816 | Val.Interna: 0.5746\n",
      "\n",
      "  Resultados da Rodada 2:\n",
      "     AcurÃ¡cia MÃ©dia: 0.5779 Â± 0.0105\n",
      "     Min: 0.5595 | Max: 0.5975\n",
      "\n",
      "RODADA 3/3\n",
      "----------------------------------------\n",
      "Fold Externo 1/10 - AcurÃ¡cia: 0.5613 | Val.Interna: 0.5733\n",
      "Fold Externo 2/10 - AcurÃ¡cia: 0.5723 | Val.Interna: 0.5748\n",
      "Fold Externo 3/10 - AcurÃ¡cia: 0.5890 | Val.Interna: 0.5724\n",
      "Fold Externo 4/10 - AcurÃ¡cia: 0.5791 | Val.Interna: 0.5723\n",
      "Fold Externo 5/10 - AcurÃ¡cia: 0.5939 | Val.Interna: 0.5731\n",
      "Fold Externo 6/10 - AcurÃ¡cia: 0.5730 | Val.Interna: 0.5832\n",
      "Fold Externo 7/10 - AcurÃ¡cia: 0.5963 | Val.Interna: 0.5750\n",
      "Fold Externo 8/10 - AcurÃ¡cia: 0.5853 | Val.Interna: 0.5738\n",
      "Fold Externo 9/10 - AcurÃ¡cia: 0.5926 | Val.Interna: 0.5741\n",
      "Fold Externo 10/10 - AcurÃ¡cia: 0.5804 | Val.Interna: 0.5738\n",
      "\n",
      "  Resultados da Rodada 3:\n",
      "     AcurÃ¡cia MÃ©dia: 0.5823 Â± 0.0106\n",
      "     Min: 0.5613 | Max: 0.5963\n",
      "\n",
      "============================================================\n",
      "RESULTADO FINAL DAS 3 RODADAS\n",
      "============================================================\n",
      "AcurÃ¡cia Final do KNN: 0.5808 Â± 0.0020\n",
      "Intervalo de ConfianÃ§a (~95%): [0.5767, 0.5848]\n"
     ]
    }
   ],
   "source": [
    "print(\"Iniciando a validaÃ§Ã£o cruzada aninhada com KNN...\")\n",
    "print(f\"Resultado usando {len(PRE_GAME_FEATURES)} features prÃ©-jogo e {n_classes} classes.\")\n",
    "\n",
    "knn_hyperparams = {'n_neighbors':[1,3,5,7,9]}\n",
    "\n",
    "resultados_knn_pre_jogo = nested_cv_classifier(\n",
    "    df=df,\n",
    "    feature_columns=PRE_GAME_FEATURES,\n",
    "    classifier=KNeighborsClassifier(n_jobs=-1),\n",
    "    classifier_name='KNN',\n",
    "    hyperparameters=knn_hyperparams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc606313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a validaÃ§Ã£o cruzada aninhada com Decision Tree...\n",
      "Resultado usando 28 features prÃ©-jogo e 2 classes.\n",
      "Grid de hiperparÃ¢metros: 8 combinaÃ§Ãµes\n",
      "Classificador: Decision Tree\n",
      "\n",
      "RODADA 1/3\n",
      "----------------------------------------\n",
      "Fold Externo 1/10 - AcurÃ¡cia: 0.6152 | Val.Interna: 0.5915\n",
      "Fold Externo 2/10 - AcurÃ¡cia: 0.5870 | Val.Interna: 0.5931\n",
      "Fold Externo 3/10 - AcurÃ¡cia: 0.5791 | Val.Interna: 0.5857\n",
      "Fold Externo 4/10 - AcurÃ¡cia: 0.5963 | Val.Interna: 0.5956\n",
      "Fold Externo 5/10 - AcurÃ¡cia: 0.6037 | Val.Interna: 0.5966\n",
      "Fold Externo 6/10 - AcurÃ¡cia: 0.5840 | Val.Interna: 0.5941\n",
      "Fold Externo 7/10 - AcurÃ¡cia: 0.5730 | Val.Interna: 0.5889\n",
      "Fold Externo 8/10 - AcurÃ¡cia: 0.6110 | Val.Interna: 0.5878\n",
      "Fold Externo 9/10 - AcurÃ¡cia: 0.5963 | Val.Interna: 0.5959\n",
      "Fold Externo 10/10 - AcurÃ¡cia: 0.5595 | Val.Interna: 0.5915\n",
      "\n",
      "  Resultados da Rodada 1:\n",
      "     AcurÃ¡cia MÃ©dia: 0.5905 Â± 0.0165\n",
      "     Min: 0.5595 | Max: 0.6152\n",
      "\n",
      "RODADA 2/3\n",
      "----------------------------------------\n",
      "Fold Externo 1/10 - AcurÃ¡cia: 0.5760 | Val.Interna: 0.5879\n",
      "Fold Externo 2/10 - AcurÃ¡cia: 0.6189 | Val.Interna: 0.5898\n",
      "Fold Externo 3/10 - AcurÃ¡cia: 0.6049 | Val.Interna: 0.5866\n",
      "Fold Externo 4/10 - AcurÃ¡cia: 0.5840 | Val.Interna: 0.5934\n",
      "Fold Externo 5/10 - AcurÃ¡cia: 0.5767 | Val.Interna: 0.6002\n",
      "Fold Externo 6/10 - AcurÃ¡cia: 0.5877 | Val.Interna: 0.5921\n",
      "Fold Externo 7/10 - AcurÃ¡cia: 0.5755 | Val.Interna: 0.5910\n",
      "Fold Externo 8/10 - AcurÃ¡cia: 0.5951 | Val.Interna: 0.5859\n",
      "Fold Externo 9/10 - AcurÃ¡cia: 0.5877 | Val.Interna: 0.5851\n",
      "Fold Externo 10/10 - AcurÃ¡cia: 0.5779 | Val.Interna: 0.5869\n",
      "\n",
      "  Resultados da Rodada 2:\n",
      "     AcurÃ¡cia MÃ©dia: 0.5884 Â± 0.0135\n",
      "     Min: 0.5755 | Max: 0.6189\n",
      "\n",
      "RODADA 3/3\n",
      "----------------------------------------\n",
      "Fold Externo 1/10 - AcurÃ¡cia: 0.6091 | Val.Interna: 0.5901\n",
      "Fold Externo 2/10 - AcurÃ¡cia: 0.5882 | Val.Interna: 0.5871\n",
      "Fold Externo 3/10 - AcurÃ¡cia: 0.5914 | Val.Interna: 0.5873\n",
      "Fold Externo 4/10 - AcurÃ¡cia: 0.6049 | Val.Interna: 0.5955\n",
      "Fold Externo 5/10 - AcurÃ¡cia: 0.6012 | Val.Interna: 0.5876\n",
      "Fold Externo 6/10 - AcurÃ¡cia: 0.5840 | Val.Interna: 0.5842\n",
      "Fold Externo 7/10 - AcurÃ¡cia: 0.5644 | Val.Interna: 0.5911\n",
      "Fold Externo 8/10 - AcurÃ¡cia: 0.5791 | Val.Interna: 0.5895\n",
      "Fold Externo 9/10 - AcurÃ¡cia: 0.5890 | Val.Interna: 0.5891\n",
      "Fold Externo 10/10 - AcurÃ¡cia: 0.5546 | Val.Interna: 0.5899\n",
      "\n",
      "  Resultados da Rodada 3:\n",
      "     AcurÃ¡cia MÃ©dia: 0.5866 Â± 0.0163\n",
      "     Min: 0.5546 | Max: 0.6091\n",
      "\n",
      "============================================================\n",
      "RESULTADO FINAL DAS 3 RODADAS\n",
      "============================================================\n",
      "AcurÃ¡cia Final do Decision Tree: 0.5885 Â± 0.0016\n",
      "Intervalo de ConfianÃ§a (~95%): [0.5853, 0.5917]\n"
     ]
    }
   ],
   "source": [
    "print(\"Iniciando a validaÃ§Ã£o cruzada aninhada com Decision Tree...\")\n",
    "print(f\"Resultado usando {len(PRE_GAME_FEATURES)} features prÃ©-jogo e {n_classes} classes.\")\n",
    "\n",
    "dt_hyperparams = {\n",
    "    'criterion': ['gini', 'entropy'], \n",
    "    'max_depth': [5, 10, 15, 25]\n",
    "}\n",
    "\n",
    "resultados_dt_pre_jogo = nested_cv_classifier(\n",
    "    df=df,\n",
    "    feature_columns=PRE_GAME_FEATURES,\n",
    "    classifier=DecisionTreeClassifier(random_state=36854321),\n",
    "    classifier_name='Decision Tree',\n",
    "    hyperparameters=dt_hyperparams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbf8afb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a validaÃ§Ã£o cruzada aninhada com Multi Layer Perceptron...\n",
      "Resultado usando 28 features prÃ©-jogo e 2 classes.\n",
      "Grid de hiperparÃ¢metros: 8 combinaÃ§Ãµes\n",
      "Classificador: Multi Layer Perceptron\n",
      "\n",
      "RODADA 1/3\n",
      "----------------------------------------\n",
      "Fold Externo 1/10 - AcurÃ¡cia: 0.5490 | Val.Interna: 0.5802\n",
      "Fold Externo 2/10 - AcurÃ¡cia: 0.5821 | Val.Interna: 0.5871\n",
      "Fold Externo 3/10 - AcurÃ¡cia: 0.6086 | Val.Interna: 0.5899\n",
      "Fold Externo 4/10 - AcurÃ¡cia: 0.5840 | Val.Interna: 0.5817\n",
      "Fold Externo 5/10 - AcurÃ¡cia: 0.5914 | Val.Interna: 0.5858\n",
      "Fold Externo 6/10 - AcurÃ¡cia: 0.5804 | Val.Interna: 0.5893\n",
      "Fold Externo 7/10 - AcurÃ¡cia: 0.5877 | Val.Interna: 0.5898\n",
      "Fold Externo 8/10 - AcurÃ¡cia: 0.6012 | Val.Interna: 0.5857\n",
      "Fold Externo 9/10 - AcurÃ¡cia: 0.5816 | Val.Interna: 0.5865\n",
      "Fold Externo 10/10 - AcurÃ¡cia: 0.5865 | Val.Interna: 0.5891\n",
      "\n",
      "  Resultados da Rodada 1:\n",
      "     AcurÃ¡cia MÃ©dia: 0.5853 Â± 0.0149\n",
      "     Min: 0.5490 | Max: 0.6086\n",
      "\n",
      "RODADA 2/3\n",
      "----------------------------------------\n",
      "Fold Externo 1/10 - AcurÃ¡cia: 0.5882 | Val.Interna: 0.5849\n",
      "Fold Externo 2/10 - AcurÃ¡cia: 0.5907 | Val.Interna: 0.5780\n",
      "Fold Externo 3/10 - AcurÃ¡cia: 0.5779 | Val.Interna: 0.5885\n",
      "Fold Externo 4/10 - AcurÃ¡cia: 0.5890 | Val.Interna: 0.5798\n",
      "Fold Externo 5/10 - AcurÃ¡cia: 0.5828 | Val.Interna: 0.5746\n",
      "Fold Externo 6/10 - AcurÃ¡cia: 0.5926 | Val.Interna: 0.5867\n",
      "Fold Externo 7/10 - AcurÃ¡cia: 0.6012 | Val.Interna: 0.5893\n",
      "Fold Externo 8/10 - AcurÃ¡cia: 0.5742 | Val.Interna: 0.5863\n",
      "Fold Externo 9/10 - AcurÃ¡cia: 0.5509 | Val.Interna: 0.5795\n",
      "Fold Externo 10/10 - AcurÃ¡cia: 0.6098 | Val.Interna: 0.5829\n",
      "\n",
      "  Resultados da Rodada 2:\n",
      "     AcurÃ¡cia MÃ©dia: 0.5857 Â± 0.0152\n",
      "     Min: 0.5509 | Max: 0.6098\n",
      "\n",
      "RODADA 3/3\n",
      "----------------------------------------\n",
      "Fold Externo 1/10 - AcurÃ¡cia: 0.6213 | Val.Interna: 0.5757\n",
      "Fold Externo 2/10 - AcurÃ¡cia: 0.6091 | Val.Interna: 0.5829\n",
      "Fold Externo 3/10 - AcurÃ¡cia: 0.5632 | Val.Interna: 0.5872\n",
      "Fold Externo 4/10 - AcurÃ¡cia: 0.6000 | Val.Interna: 0.5738\n",
      "Fold Externo 5/10 - AcurÃ¡cia: 0.6135 | Val.Interna: 0.5902\n",
      "Fold Externo 6/10 - AcurÃ¡cia: 0.5669 | Val.Interna: 0.5874\n",
      "Fold Externo 7/10 - AcurÃ¡cia: 0.5914 | Val.Interna: 0.5820\n",
      "Fold Externo 8/10 - AcurÃ¡cia: 0.5767 | Val.Interna: 0.5881\n",
      "Fold Externo 9/10 - AcurÃ¡cia: 0.5509 | Val.Interna: 0.5853\n",
      "Fold Externo 10/10 - AcurÃ¡cia: 0.5669 | Val.Interna: 0.5791\n",
      "\n",
      "  Resultados da Rodada 3:\n",
      "     AcurÃ¡cia MÃ©dia: 0.5860 Â± 0.0231\n",
      "     Min: 0.5509 | Max: 0.6213\n",
      "\n",
      "============================================================\n",
      "RESULTADO FINAL DAS 3 RODADAS\n",
      "============================================================\n",
      "AcurÃ¡cia Final do Multi Layer Perceptron: 0.5857 Â± 0.0003\n",
      "Intervalo de ConfianÃ§a (~95%): [0.5851, 0.5863]\n"
     ]
    }
   ],
   "source": [
    "print(\"Iniciando a validaÃ§Ã£o cruzada aninhada com Multi Layer Perceptron...\")\n",
    "print(f\"Resultado usando {len(PRE_GAME_FEATURES)} features prÃ©-jogo e {n_classes} classes.\")\n",
    "\n",
    "mlp_hyperparams = {\n",
    "    'hidden_layer_sizes': [(100,), (10,)],\n",
    "    'alpha': [0.0001, 0.005],\n",
    "    'learning_rate': ['constant', 'adaptive']\n",
    "}\n",
    "\n",
    "resultados_mlp_pre_jogo = nested_cv_classifier(\n",
    "    df=df,\n",
    "    feature_columns=PRE_GAME_FEATURES,\n",
    "    classifier=MLPClassifier(random_state=36854321, max_iter=1000),\n",
    "    classifier_name='Multi Layer Perceptron',\n",
    "    hyperparameters=mlp_hyperparams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1b211b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a validaÃ§Ã£o cruzada aninhada com Heterogeneous Boosting Classifier...\n",
      "Resultado usando 28 features prÃ©-jogo e 2 classes.\n",
      "Grid de hiperparÃ¢metros: 5 combinaÃ§Ãµes\n",
      "Classificador: Heterogeneous Boosting\n",
      "\n",
      "RODADA 1/3\n",
      "----------------------------------------\n",
      "Fold Externo 1/10 - AcurÃ¡cia: 0.5772 | Val.Interna: 0.5706\n",
      "Fold Externo 2/10 - AcurÃ¡cia: 0.5637 | Val.Interna: 0.5751\n",
      "Fold Externo 3/10 - AcurÃ¡cia: 0.5730 | Val.Interna: 0.5741\n",
      "Fold Externo 4/10 - AcurÃ¡cia: 0.5730 | Val.Interna: 0.5726\n",
      "Fold Externo 5/10 - AcurÃ¡cia: 0.5865 | Val.Interna: 0.5783\n",
      "Fold Externo 6/10 - AcurÃ¡cia: 0.5730 | Val.Interna: 0.5780\n",
      "Fold Externo 7/10 - AcurÃ¡cia: 0.6012 | Val.Interna: 0.5734\n",
      "Fold Externo 8/10 - AcurÃ¡cia: 0.5804 | Val.Interna: 0.5782\n",
      "Fold Externo 9/10 - AcurÃ¡cia: 0.5730 | Val.Interna: 0.5654\n",
      "Fold Externo 10/10 - AcurÃ¡cia: 0.5963 | Val.Interna: 0.5831\n",
      "\n",
      "  Resultados da Rodada 1:\n",
      "     AcurÃ¡cia MÃ©dia: 0.5797 Â± 0.0111\n",
      "     Min: 0.5637 | Max: 0.6012\n",
      "\n",
      "RODADA 2/3\n",
      "----------------------------------------\n",
      "Fold Externo 1/10 - AcurÃ¡cia: 0.5502 | Val.Interna: 0.5806\n",
      "Fold Externo 2/10 - AcurÃ¡cia: 0.5797 | Val.Interna: 0.5789\n",
      "Fold Externo 3/10 - AcurÃ¡cia: 0.5509 | Val.Interna: 0.5709\n",
      "Fold Externo 4/10 - AcurÃ¡cia: 0.6098 | Val.Interna: 0.5769\n",
      "Fold Externo 5/10 - AcurÃ¡cia: 0.5853 | Val.Interna: 0.5842\n",
      "Fold Externo 6/10 - AcurÃ¡cia: 0.5865 | Val.Interna: 0.5806\n",
      "Fold Externo 7/10 - AcurÃ¡cia: 0.6184 | Val.Interna: 0.5753\n",
      "Fold Externo 8/10 - AcurÃ¡cia: 0.5951 | Val.Interna: 0.5801\n",
      "Fold Externo 9/10 - AcurÃ¡cia: 0.5963 | Val.Interna: 0.5722\n",
      "Fold Externo 10/10 - AcurÃ¡cia: 0.5730 | Val.Interna: 0.5735\n",
      "\n",
      "  Resultados da Rodada 2:\n",
      "     AcurÃ¡cia MÃ©dia: 0.5845 Â± 0.0212\n",
      "     Min: 0.5502 | Max: 0.6184\n",
      "\n",
      "RODADA 3/3\n",
      "----------------------------------------\n",
      "Fold Externo 1/10 - AcurÃ¡cia: 0.5502 | Val.Interna: 0.5806\n",
      "Fold Externo 2/10 - AcurÃ¡cia: 0.5797 | Val.Interna: 0.5789\n",
      "Fold Externo 3/10 - AcurÃ¡cia: 0.5509 | Val.Interna: 0.5709\n",
      "Fold Externo 4/10 - AcurÃ¡cia: 0.6098 | Val.Interna: 0.5769\n",
      "Fold Externo 5/10 - AcurÃ¡cia: 0.5853 | Val.Interna: 0.5842\n",
      "Fold Externo 6/10 - AcurÃ¡cia: 0.5865 | Val.Interna: 0.5806\n",
      "Fold Externo 7/10 - AcurÃ¡cia: 0.6184 | Val.Interna: 0.5753\n",
      "Fold Externo 8/10 - AcurÃ¡cia: 0.5951 | Val.Interna: 0.5801\n",
      "Fold Externo 9/10 - AcurÃ¡cia: 0.5963 | Val.Interna: 0.5722\n",
      "Fold Externo 10/10 - AcurÃ¡cia: 0.5730 | Val.Interna: 0.5735\n",
      "\n",
      "  Resultados da Rodada 3:\n",
      "     AcurÃ¡cia MÃ©dia: 0.5845 Â± 0.0212\n",
      "     Min: 0.5502 | Max: 0.6184\n",
      "\n",
      "============================================================\n",
      "RESULTADO FINAL DAS 3 RODADAS\n",
      "============================================================\n",
      "AcurÃ¡cia Final do Heterogeneous Boosting: 0.5829 Â± 0.0023\n",
      "Intervalo de ConfianÃ§a (~95%): [0.5784, 0.5874]\n"
     ]
    }
   ],
   "source": [
    "print(\"Iniciando a validaÃ§Ã£o cruzada aninhada com Heterogeneous Boosting Classifier...\")\n",
    "print(f\"Resultado usando {len(PRE_GAME_FEATURES)} features prÃ©-jogo e {n_classes} classes.\")\n",
    "\n",
    "hb = HeterogeneousBoostingClassifier(n_estimators=5, random_state=36854321)\n",
    "hb_hyperparams = {'n_estimators': [5, 10, 15, 25, 50]}\n",
    "\n",
    "resultados_hb_pre_jogo = nested_cv_classifier(\n",
    "    df=df,\n",
    "    feature_columns=PRE_GAME_FEATURES,\n",
    "    classifier=hb,\n",
    "    classifier_name='Heterogeneous Boosting',\n",
    "    hyperparameters=hb_hyperparams,\n",
    "    target_column=TARGET,\n",
    "    n_classes=n_classes,\n",
    "    n_outer_folds=10,\n",
    "    n_inner_folds=4,\n",
    "    n_rounds=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be3f60b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hb_scores =  resultados_hb_pre_jogo['resultados_completos']['acuracia_media']\n",
    "dt_scores = resultados_dt_pre_jogo['resultados_completos']['acuracia_media']\n",
    "knn_scores = resultados_knn_pre_jogo['resultados_completos']['acuracia_media']\n",
    "mlp_scores = resultados_mlp_pre_jogo['resultados_completos']['acuracia_media']\n",
    "rf_scores = resultados_rf_pre_jogo['resultados_completos']['acuracia_media']\n",
    "\n",
    "# Resultados de cada classificador (exemplo com dicionÃ¡rio)\n",
    "results = {\n",
    "    'DT': dt_scores,\n",
    "    'KNN': knn_scores,\n",
    "    'MLP': mlp_scores,\n",
    "    'RF': rf_scores,\n",
    "    'HB': hb_scores\n",
    "}\n",
    "\n",
    "# Boxplot dos classificadores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=pd.DataFrame(results))\n",
    "plt.title(\"Boxplot das acurÃ¡cias por classificador\")\n",
    "plt.ylabel(\"AcurÃ¡cia\")\n",
    "plt.xlabel(\"Classificador\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32598d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  MÃ©todo   MÃ©dia  Desvio PadrÃ£o  Limite Inferior  Limite Superior\n",
      "0     DT  0.5885         0.0020           0.5871           0.5899\n",
      "1    KNN  0.5808         0.0025           0.5790           0.5825\n",
      "2    MLP  0.5857         0.0004           0.5854           0.5859\n",
      "3     RF  0.6136         0.0018           0.6123           0.6148\n",
      "4     HB  0.5829         0.0028           0.5810           0.5849\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy.stats import t\n",
    "import numpy as np\n",
    "\n",
    "def compute_stats(scores_dict, n_folds):\n",
    "    summary = []\n",
    "    for method, scores in scores_dict.items():\n",
    "        mean = np.mean(scores)\n",
    "        std = np.std(scores, ddof=1)\n",
    "        ci = t.ppf(0.975, n_folds-1) * std / np.sqrt(n_folds)\n",
    "        summary.append([method, round(mean, 4), round(std, 4),\n",
    "                        round(mean - ci, 4), round(mean + ci, 4)])\n",
    "    return pd.DataFrame(summary, columns=[\"MÃ©todo\", \"MÃ©dia\", \"Desvio PadrÃ£o\", \"Limite Inferior\", \"Limite Superior\"])\n",
    "\n",
    "stats_table = compute_stats(results, n_folds=10)\n",
    "print(stats_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c4fb72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    DT 0.0674 0.2067 **0.0083**     0.2091\n",
      "0.2500    KNN 0.1027 **0.0012**     0.5424\n",
      "0.2500 0.2500    MLP **0.0015**     0.2318\n",
      "0.2500 0.2500 0.2500         RF **0.0038**\n",
      "0.2500 0.7500 0.2500     0.2500         HB\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from scipy.stats import t\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# FunÃ§Ã£o do teste t corrigido de Nadeau e Bengio\n",
    "def t_corrigido_nadeau_bengio(data1, data2, X, n_folds_externos):\n",
    "    N = len(X)\n",
    "    n = len(data1)\n",
    "    n_test = N // n_folds_externos\n",
    "    n_train = N - n_test\n",
    "    diffs = np.array(data1) - np.array(data2)\n",
    "    mean_diff = np.mean(diffs)\n",
    "    std_diff = np.std(diffs, ddof=1)\n",
    "    se_corrigido = std_diff * np.sqrt(1/n + n_test/n_train)\n",
    "    t_stat = mean_diff / se_corrigido\n",
    "    p_valor = 2 * (1 - t.cdf(abs(t_stat), df=n - 1))\n",
    "    return t_stat, p_valor\n",
    "\n",
    "# Preparar os dados\n",
    "metodos = list(results.keys())  # results = {'DT': [...], 'KNN': [...], ...}\n",
    "n_metodos = len(metodos)\n",
    "N = len(X)  # X precisa ser o conjunto de dados original\n",
    "n_folds_externos = 10\n",
    "\n",
    "# Inicializa matriz de p-valores\n",
    "matriz_p = np.empty((n_metodos, n_metodos), dtype=object)\n",
    "\n",
    "# Preenche a matriz com os testes\n",
    "for i in range(n_metodos):\n",
    "    for j in range(n_metodos):\n",
    "        if i == j:\n",
    "            matriz_p[i, j] = metodos[i]\n",
    "        elif i < j:\n",
    "            _, p = t_corrigido_nadeau_bengio(results[metodos[i]], results[metodos[j]], X, n_folds_externos)\n",
    "            matriz_p[i, j] = f\"**{p:.4f}**\" if p < 0.05 else f\"{p:.4f}\"\n",
    "        else:\n",
    "            _, p = stats.wilcoxon(results[metodos[i]], results[metodos[j]])\n",
    "            matriz_p[i, j] = f\"**{p:.4f}**\" if p < 0.05 else f\"{p:.4f}\"\n",
    "\n",
    "# Exibir a matriz formatada\n",
    "tabela_pvalues = pd.DataFrame(matriz_p, index=metodos, columns=metodos)\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(tabela_pvalues.to_string(index=False, header=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
